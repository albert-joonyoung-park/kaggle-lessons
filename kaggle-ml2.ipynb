{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-20T13:56:59.878241Z","iopub.execute_input":"2023-07-20T13:56:59.878671Z","iopub.status.idle":"2023-07-20T13:56:59.893551Z","shell.execute_reply.started":"2023-07-20T13:56:59.878636Z","shell.execute_reply":"2023-07-20T13:56:59.892334Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/melbourne-housing-snapshot/melb_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Missing values   \n* Drop columns with NaN\n* Imputation\n* Extension to imputation","metadata":{}},{"cell_type":"markdown","source":"**Load modules and data**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the data\ndata = pd.read_csv('/kaggle/input/melbourne-housing-snapshot/melb_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:56:59.895643Z","iopub.execute_input":"2023-07-20T13:56:59.896418Z","iopub.status.idle":"2023-07-20T13:57:00.789484Z","shell.execute_reply.started":"2023-07-20T13:56:59.896384Z","shell.execute_reply":"2023-07-20T13:57:00.788248Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# check the data, look for missing values\nprint(data.head())                       # review data, missing values\nprint(\"_\" * 70)\nprint(data.dtypes, type(data.dtypes))    # what are the column types?\nprint(\"_\" * 70)\ndata.dtypes.value_counts()               # column_type - count\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-20T13:57:00.790989Z","iopub.execute_input":"2023-07-20T13:57:00.791453Z","iopub.status.idle":"2023-07-20T13:57:00.834938Z","shell.execute_reply.started":"2023-07-20T13:57:00.791410Z","shell.execute_reply":"2023-07-20T13:57:00.833743Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"       Suburb           Address  Rooms Type      Price Method SellerG  \\\n0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n\n        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n0  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n3  4/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n\n   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n\n  Propertycount  \n0        4019.0  \n1        4019.0  \n2        4019.0  \n3        4019.0  \n4        4019.0  \n\n[5 rows x 21 columns]\n______________________________________________________________________\nSuburb            object\nAddress           object\nRooms              int64\nType              object\nPrice            float64\nMethod            object\nSellerG           object\nDate              object\nDistance         float64\nPostcode         float64\nBedroom2         float64\nBathroom         float64\nCar              float64\nLandsize         float64\nBuildingArea     float64\nYearBuilt        float64\nCouncilArea       object\nLattitude        float64\nLongtitude       float64\nRegionname        object\nPropertycount    float64\ndtype: object <class 'pandas.core.series.Series'>\n______________________________________________________________________\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"float64    12\nobject      8\nint64       1\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**What is the model going to predict?**","metadata":{}},{"cell_type":"code","source":"# The model will predict the 'Price' of the dataset \ny = data.Price","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.837883Z","iopub.execute_input":"2023-07-20T13:57:00.841135Z","iopub.status.idle":"2023-07-20T13:57:00.846725Z","shell.execute_reply.started":"2023-07-20T13:57:00.841065Z","shell.execute_reply":"2023-07-20T13:57:00.845266Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Prepare features(predictors)**   \nWill only use numeric type columns as predictors","metadata":{}},{"cell_type":"code","source":"melb_predictors = data.drop(['Price'], axis=1)         # drop column 'Price', being target column\nX = melb_predictors.select_dtypes(exclude=['object'])  # as-per the requirement, keep only numeric / boolean valued columns","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.849491Z","iopub.execute_input":"2023-07-20T13:57:00.850314Z","iopub.status.idle":"2023-07-20T13:57:00.868716Z","shell.execute_reply.started":"2023-07-20T13:57:00.850269Z","shell.execute_reply":"2023-07-20T13:57:00.867505Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# check the new filtered data frames with predictors(features)\nX\n# The predictors are ready","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.872453Z","iopub.execute_input":"2023-07-20T13:57:00.873539Z","iopub.status.idle":"2023-07-20T13:57:00.910330Z","shell.execute_reply.started":"2023-07-20T13:57:00.873412Z","shell.execute_reply":"2023-07-20T13:57:00.909205Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n0          2       2.5    3067.0       2.0       1.0  1.0     202.0   \n1          2       2.5    3067.0       2.0       1.0  0.0     156.0   \n2          3       2.5    3067.0       3.0       2.0  0.0     134.0   \n3          3       2.5    3067.0       3.0       2.0  1.0      94.0   \n4          4       2.5    3067.0       3.0       1.0  2.0     120.0   \n...      ...       ...       ...       ...       ...  ...       ...   \n13575      4      16.7    3150.0       4.0       2.0  2.0     652.0   \n13576      3       6.8    3016.0       3.0       2.0  2.0     333.0   \n13577      3       6.8    3016.0       3.0       2.0  4.0     436.0   \n13578      4       6.8    3016.0       4.0       1.0  5.0     866.0   \n13579      4       6.3    3013.0       4.0       1.0  1.0     362.0   \n\n       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n0               NaN        NaN  -37.79960   144.99840         4019.0  \n1              79.0     1900.0  -37.80790   144.99340         4019.0  \n2             150.0     1900.0  -37.80930   144.99440         4019.0  \n3               NaN        NaN  -37.79690   144.99690         4019.0  \n4             142.0     2014.0  -37.80720   144.99410         4019.0  \n...             ...        ...        ...         ...            ...  \n13575           NaN     1981.0  -37.90562   145.16761         7392.0  \n13576         133.0     1995.0  -37.85927   144.87904         6380.0  \n13577           NaN     1997.0  -37.85274   144.88738         6380.0  \n13578         157.0     1920.0  -37.85908   144.89299         6380.0  \n13579         112.0     1920.0  -37.81188   144.88449         6543.0  \n\n[13580 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rooms</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>Bedroom2</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>202.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-37.79960</td>\n      <td>144.99840</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>156.0</td>\n      <td>79.0</td>\n      <td>1900.0</td>\n      <td>-37.80790</td>\n      <td>144.99340</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>134.0</td>\n      <td>150.0</td>\n      <td>1900.0</td>\n      <td>-37.80930</td>\n      <td>144.99440</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-37.79690</td>\n      <td>144.99690</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>120.0</td>\n      <td>142.0</td>\n      <td>2014.0</td>\n      <td>-37.80720</td>\n      <td>144.99410</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13575</th>\n      <td>4</td>\n      <td>16.7</td>\n      <td>3150.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>652.0</td>\n      <td>NaN</td>\n      <td>1981.0</td>\n      <td>-37.90562</td>\n      <td>145.16761</td>\n      <td>7392.0</td>\n    </tr>\n    <tr>\n      <th>13576</th>\n      <td>3</td>\n      <td>6.8</td>\n      <td>3016.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>333.0</td>\n      <td>133.0</td>\n      <td>1995.0</td>\n      <td>-37.85927</td>\n      <td>144.87904</td>\n      <td>6380.0</td>\n    </tr>\n    <tr>\n      <th>13577</th>\n      <td>3</td>\n      <td>6.8</td>\n      <td>3016.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>436.0</td>\n      <td>NaN</td>\n      <td>1997.0</td>\n      <td>-37.85274</td>\n      <td>144.88738</td>\n      <td>6380.0</td>\n    </tr>\n    <tr>\n      <th>13578</th>\n      <td>4</td>\n      <td>6.8</td>\n      <td>3016.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>866.0</td>\n      <td>157.0</td>\n      <td>1920.0</td>\n      <td>-37.85908</td>\n      <td>144.89299</td>\n      <td>6380.0</td>\n    </tr>\n    <tr>\n      <th>13579</th>\n      <td>4</td>\n      <td>6.3</td>\n      <td>3013.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>362.0</td>\n      <td>112.0</td>\n      <td>1920.0</td>\n      <td>-37.81188</td>\n      <td>144.88449</td>\n      <td>6543.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13580 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Split data into training and validation subsets**","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.912084Z","iopub.execute_input":"2023-07-20T13:57:00.913311Z","iopub.status.idle":"2023-07-20T13:57:00.923307Z","shell.execute_reply.started":"2023-07-20T13:57:00.913266Z","shell.execute_reply":"2023-07-20T13:57:00.922309Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# the data seems it's splited correctly\nprint(X_train)\nprint(y_train)\nprint(X_valid)\nprint(y_valid)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.925290Z","iopub.execute_input":"2023-07-20T13:57:00.926431Z","iopub.status.idle":"2023-07-20T13:57:00.965800Z","shell.execute_reply.started":"2023-07-20T13:57:00.926384Z","shell.execute_reply":"2023-07-20T13:57:00.964332Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n12167      1       5.0    3182.0       1.0       1.0  1.0       0.0   \n6524       2       8.0    3016.0       2.0       2.0  1.0     193.0   \n8413       3      12.6    3020.0       3.0       1.0  1.0     555.0   \n2919       3      13.0    3046.0       3.0       1.0  1.0     265.0   \n6043       3      13.3    3020.0       3.0       1.0  2.0     673.0   \n...      ...       ...       ...       ...       ...  ...       ...   \n13123      3       5.2    3056.0       3.0       1.0  2.0     212.0   \n3264       3      10.5    3081.0       3.0       1.0  1.0     748.0   \n9845       4       6.7    3058.0       4.0       2.0  2.0     441.0   \n10799      3      12.0    3073.0       3.0       1.0  1.0     606.0   \n2732       4       6.4    3011.0       4.0       2.0  1.0     319.0   \n\n       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n12167           NaN     1940.0  -37.85984   144.98670        13240.0  \n6524            NaN        NaN  -37.85800   144.90050         6380.0  \n8413            NaN        NaN  -37.79880   144.82200         3755.0  \n2919            NaN     1995.0  -37.70830   144.91580         8870.0  \n6043          673.0     1970.0  -37.76230   144.82720         4217.0  \n...             ...        ...        ...         ...            ...  \n13123           NaN        NaN  -37.77695   144.95785        11918.0  \n3264          101.0     1950.0  -37.74160   145.04810         2947.0  \n9845          255.0     2002.0  -37.73572   144.97256        11204.0  \n10799           NaN        NaN  -37.72057   145.02615        21650.0  \n2732          130.0     1915.0  -37.79430   144.88750         7570.0  \n\n[10864 rows x 12 columns]\n12167     481000.0\n6524      895000.0\n8413      651500.0\n2919      482500.0\n6043      591000.0\n           ...    \n13123    1280000.0\n3264      915000.0\n9845     1020000.0\n10799     760000.0\n2732     1225000.0\nName: Price, Length: 10864, dtype: float64\n       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n8505       4       8.0    3016.0       4.0       2.0  2.0     450.0   \n5523       2       6.6    3011.0       2.0       1.0  0.0     172.0   \n12852      3      10.5    3020.0       3.0       1.0  1.0     581.0   \n4818       3       4.5    3181.0       2.0       2.0  1.0     128.0   \n12812      3       8.5    3044.0       3.0       2.0  2.0     480.0   \n...      ...       ...       ...       ...       ...  ...       ...   \n2664       2       6.4    3011.0       2.0       1.0  1.0      47.0   \n8513       4       8.0    3016.0       4.0       2.0  4.0     551.0   \n12922      3      10.8    3105.0       3.0       1.0  1.0     757.0   \n10761      4       6.2    3039.0       4.0       1.0  3.0     478.0   \n2110       2       1.6    3066.0       2.0       1.0  2.0     159.0   \n\n       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n8505          190.0     1910.0  -37.86100   144.89850         6380.0  \n5523           81.0     1900.0  -37.81000   144.88960         2417.0  \n12852           NaN        NaN  -37.76740   144.82421         4217.0  \n4818          134.0     2000.0  -37.85260   145.00710         7717.0  \n12812           NaN        NaN  -37.72523   144.94567         7485.0  \n...             ...        ...        ...         ...            ...  \n2664           35.0     2013.0  -37.80140   144.89590         7570.0  \n8513            NaN        NaN  -37.85790   144.87860         6380.0  \n12922           NaN        NaN  -37.78094   145.10131         4480.0  \n10761         152.0     1925.0  -37.76421   144.90571         6232.0  \n2110           86.0     1880.0  -37.79620   144.98870         4553.0  \n\n[2716 rows x 12 columns]\n8505     2165000.0\n5523      815000.0\n12852     610000.0\n4818     1245000.0\n12812    1160000.0\n           ...    \n2664      305000.0\n8513     1412000.0\n12922    1230000.0\n10761    1270000.0\n2110     1000000.0\nName: Price, Length: 2716, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Try Three approaches with the model and compare the prediction peformance of each model**","metadata":{}},{"cell_type":"code","source":"# Approach 1 - Dropping columns with NaN\n\n# What columns have missing values?\ncols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()] # if any element in the column is null, then True\nprint(\"The columns with missing values: \", cols_with_missing) \nprint(\"_\" * 70)\n\n# Drop the colums in both training and validation dataset\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\nprint(reduced_X_train) \nprint(\"_\" * 70)\n\nprint(reduced_X_valid) \nprint(\"_\" * 70)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:00.971800Z","iopub.execute_input":"2023-07-20T13:57:00.972266Z","iopub.status.idle":"2023-07-20T13:57:01.017391Z","shell.execute_reply.started":"2023-07-20T13:57:00.972228Z","shell.execute_reply":"2023-07-20T13:57:01.015907Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"The columns with missing values:  ['Car', 'BuildingArea', 'YearBuilt']\n______________________________________________________________________\n       Rooms  Distance  Postcode  Bedroom2  Bathroom  Landsize  Lattitude  \\\n12167      1       5.0    3182.0       1.0       1.0       0.0  -37.85984   \n6524       2       8.0    3016.0       2.0       2.0     193.0  -37.85800   \n8413       3      12.6    3020.0       3.0       1.0     555.0  -37.79880   \n2919       3      13.0    3046.0       3.0       1.0     265.0  -37.70830   \n6043       3      13.3    3020.0       3.0       1.0     673.0  -37.76230   \n...      ...       ...       ...       ...       ...       ...        ...   \n13123      3       5.2    3056.0       3.0       1.0     212.0  -37.77695   \n3264       3      10.5    3081.0       3.0       1.0     748.0  -37.74160   \n9845       4       6.7    3058.0       4.0       2.0     441.0  -37.73572   \n10799      3      12.0    3073.0       3.0       1.0     606.0  -37.72057   \n2732       4       6.4    3011.0       4.0       2.0     319.0  -37.79430   \n\n       Longtitude  Propertycount  \n12167   144.98670        13240.0  \n6524    144.90050         6380.0  \n8413    144.82200         3755.0  \n2919    144.91580         8870.0  \n6043    144.82720         4217.0  \n...           ...            ...  \n13123   144.95785        11918.0  \n3264    145.04810         2947.0  \n9845    144.97256        11204.0  \n10799   145.02615        21650.0  \n2732    144.88750         7570.0  \n\n[10864 rows x 9 columns]\n______________________________________________________________________\n       Rooms  Distance  Postcode  Bedroom2  Bathroom  Landsize  Lattitude  \\\n8505       4       8.0    3016.0       4.0       2.0     450.0  -37.86100   \n5523       2       6.6    3011.0       2.0       1.0     172.0  -37.81000   \n12852      3      10.5    3020.0       3.0       1.0     581.0  -37.76740   \n4818       3       4.5    3181.0       2.0       2.0     128.0  -37.85260   \n12812      3       8.5    3044.0       3.0       2.0     480.0  -37.72523   \n...      ...       ...       ...       ...       ...       ...        ...   \n2664       2       6.4    3011.0       2.0       1.0      47.0  -37.80140   \n8513       4       8.0    3016.0       4.0       2.0     551.0  -37.85790   \n12922      3      10.8    3105.0       3.0       1.0     757.0  -37.78094   \n10761      4       6.2    3039.0       4.0       1.0     478.0  -37.76421   \n2110       2       1.6    3066.0       2.0       1.0     159.0  -37.79620   \n\n       Longtitude  Propertycount  \n8505    144.89850         6380.0  \n5523    144.88960         2417.0  \n12852   144.82421         4217.0  \n4818    145.00710         7717.0  \n12812   144.94567         7485.0  \n...           ...            ...  \n2664    144.89590         7570.0  \n8513    144.87860         6380.0  \n12922   145.10131         4480.0  \n10761   144.90571         6232.0  \n2110    144.98870         4553.0  \n\n[2716 rows x 9 columns]\n______________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Define a helper function to evaluate the model performance, to be used for each model with different approaches (handling missing values), using Random Forest model from scikit-learn, MAE method**","metadata":{}},{"cell_type":"code","source":"# modules\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# function to build a rnadom forest model and return MAE performance\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=10, random_state=0)   # create a model\n    model.fit(X_train, y_train)   # train the model\n    preds = model.predict(X_valid)      # model prediction\n    return mean_absolute_error(y_valid, preds)   # return MEA evaluation of real resut vs prediction","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:01.020157Z","iopub.execute_input":"2023-07-20T13:57:01.023826Z","iopub.status.idle":"2023-07-20T13:57:01.490923Z","shell.execute_reply.started":"2023-07-20T13:57:01.023778Z","shell.execute_reply":"2023-07-20T13:57:01.489562Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Approach 1 - Simply drop the columns with missing values\nprint(\"MAE from Approach 1 (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:01.492637Z","iopub.execute_input":"2023-07-20T13:57:01.493240Z","iopub.status.idle":"2023-07-20T13:57:02.067364Z","shell.execute_reply.started":"2023-07-20T13:57:01.493190Z","shell.execute_reply":"2023-07-20T13:57:02.065992Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"MAE from Approach 1 (Drop columns with missing values):\n183550.22137772635\n","output_type":"stream"}]},{"cell_type":"code","source":"# Approach 2 - Imputation - Fill the missing values with imputation 'strategy'\n# the process of filling in missing values with appropriate replacements, enabling the data to be used effectively in machine learning algorithms.\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nimputer = SimpleImputer() # default strategy='mean'\n\n# fit the imputer into the data and transform the data - train, valid dataset both\n# Be aware the df will loose column names after imputation\n# Make the imputed dataset as DataFrame, so you can restore columns to it, otherwise it will remain ans ndarray\nimputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(imputer.fit_transform(X_valid))\n#print(imputed_X_train.columns)\n#print(imputed_X_train)\n#print(imputed_X_valid.columns)\n#print(imputed_X_valid)\n\n# Restore the column names for the imputed data (ndarray)\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n#print(imputed_X_train.columns)\n#print(imputed_X_train)\n#print(imputed_X_valid.columns)\n#print(imputed_X_valid)\n\n# Evaluate the model using the helper function\nprint(\"MAE from Approach 2 (Imputation): \")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n\n# Note that WApproach 2 has lower MAE than Approach 1, so Approach 2 performed better on this dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-20T13:57:02.068769Z","iopub.execute_input":"2023-07-20T13:57:02.069146Z","iopub.status.idle":"2023-07-20T13:57:02.799094Z","shell.execute_reply.started":"2023-07-20T13:57:02.069100Z","shell.execute_reply":"2023-07-20T13:57:02.797945Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Imputation): \n179816.89508731329\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Note that Approach 2 has lower MAE than Approach 1, so Approach 2 performed better on this dataset**","metadata":{}},{"cell_type":"code","source":"# Approach e - Extension to Imputation - Apply Imputation as approach2, with indication for the columns that are imputed\n\n# Work with copies of the original datasets, Will add flag comlumns to them.\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# What columns are you imputing? Make new columns to mark them with Boolean value.\n# Any column with null value(NaN) will be imputed.\n# Make new colums for them, and mark with Boolean value\nfor col in cols_with_missing:\n    X_train_plus[col + '_was_missing'] = X_train[col].isnull()  # True if the cell(value) was null\n    X_valid_plus[col + '_was_missing'] = X_valid[col].isnull()  # True if the cell(value) was null\n\n# Check the relevant columns quickly and verify if the values are correct, side-by-side\nX_train_plus.loc[:,cols_with_missing + [col+'_was_missing' for col in cols_with_missing]]\n# The new columns look good.\n\n# Now impute the columns with missing values as Approach 2.\nimputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(imputer.fit_transform(X_valid_plus))\n\n# Restore columns to the new df, where lost during imputation\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\n# Check the new df's quickly\nimputed_X_train_plus\nimputed_X_valid_plus\n# Now see, no NaN columns and new flag columns with 1 or 0 values\n\n# Evaluate the model using the helper function\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n# Now see that Approach 3 performed slightly worse than Approach 2.\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:30:12.829404Z","iopub.execute_input":"2023-07-20T14:30:12.829953Z","iopub.status.idle":"2023-07-20T14:30:13.636283Z","shell.execute_reply.started":"2023-07-20T14:30:12.829915Z","shell.execute_reply":"2023-07-20T14:30:13.634888Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (An Extension to Imputation):\n179986.2708570026\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Now see that Approach 3 performed slightly worse than Approach 2.**","metadata":{}},{"cell_type":"markdown","source":"**So, why did imputation perform better than dropping the columns?**    \n> The training data has 10864 rows and 12 columns, where three columns contain missing data. For each column, less than half of the entries are missing. Thus, dropping the columns removes a lot of useful information, and so it makes sense that imputation would perform better.","metadata":{}},{"cell_type":"code","source":"print(df.shape)   # the shape of the df\nprint(\"_\" * 70)\n\ndf = X_train.isnull()   # true / false for each cell of X_train df\nprint(df) \nprint(\"_\" * 70)\n\nmissing_val_count_by_column = X_train.isnull().sum()   # add up all 1's (=True), aggregated by each column label\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])   # filter and get the columns with missing values\nprint(type(missing_val_count_by_column))","metadata":{"execution":{"iopub.status.busy":"2023-07-20T14:39:06.998606Z","iopub.execute_input":"2023-07-20T14:39:06.999042Z","iopub.status.idle":"2023-07-20T14:39:07.018571Z","shell.execute_reply.started":"2023-07-20T14:39:06.999009Z","shell.execute_reply":"2023-07-20T14:39:07.016965Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"(10864, 12)\n______________________________________________________________________\n       Rooms  Distance  Postcode  Bedroom2  Bathroom    Car  Landsize  \\\n12167  False     False     False     False     False  False     False   \n6524   False     False     False     False     False  False     False   \n8413   False     False     False     False     False  False     False   \n2919   False     False     False     False     False  False     False   \n6043   False     False     False     False     False  False     False   \n...      ...       ...       ...       ...       ...    ...       ...   \n13123  False     False     False     False     False  False     False   \n3264   False     False     False     False     False  False     False   \n9845   False     False     False     False     False  False     False   \n10799  False     False     False     False     False  False     False   \n2732   False     False     False     False     False  False     False   \n\n       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n12167          True      False      False       False          False  \n6524           True       True      False       False          False  \n8413           True       True      False       False          False  \n2919           True      False      False       False          False  \n6043          False      False      False       False          False  \n...             ...        ...        ...         ...            ...  \n13123          True       True      False       False          False  \n3264          False      False      False       False          False  \n9845          False      False      False       False          False  \n10799          True       True      False       False          False  \n2732          False      False      False       False          False  \n\n[10864 rows x 12 columns]\n______________________________________________________________________\nCar               49\nBuildingArea    5156\nYearBuilt       4307\ndtype: int64\n<class 'pandas.core.series.Series'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# As is common, imputing missing values (in Approach 2 and Approach 3) yielded better results, relative to when we simply dropped columns with missing values (in Approach 1).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}