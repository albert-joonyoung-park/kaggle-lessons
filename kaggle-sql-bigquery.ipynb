{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-02T12:23:18.905236Z","iopub.execute_input":"2023-08-02T12:23:18.906291Z","iopub.status.idle":"2023-08-02T12:23:18.941548Z","shell.execute_reply.started":"2023-08-02T12:23:18.906238Z","shell.execute_reply":"2023-08-02T12:23:18.940514Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Topics\n1. **Getting Started With SQL and BigQuery**: Workflow for handling big datasets with BigQuery and SQL\n1. **Select, From & Where**: Foundational components for all SQL queries\n1. **Group By, Having & Count**: Get more interesting insights directly from SQL queries\n1. Order the results and focus on them ost important data for use case\n1. Organize queries for better readability, important for complex queries\n1. Combine data sources for almost all real-world data problems","metadata":{}},{"cell_type":"markdown","source":"## 1. Getting Started With SQL and BigQuery","metadata":{}},{"cell_type":"code","source":"# import Python package for BigQuery\nfrom google.cloud import bigquery","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:31:33.315455Z","iopub.execute_input":"2023-08-02T12:31:33.316305Z","iopub.status.idle":"2023-08-02T12:31:33.321035Z","shell.execute_reply.started":"2023-08-02T12:31:33.316272Z","shell.execute_reply":"2023-08-02T12:31:33.319803Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create a Client object, retrieving info. from BigQuery\nclient = bigquery.Client()  # Using Kaggle's public dataset BigQuery integration.","metadata":{"execution":{"iopub.status.busy":"2023-08-02T12:32:05.678851Z","iopub.execute_input":"2023-08-02T12:32:05.679234Z","iopub.status.idle":"2023-08-02T12:32:05.685218Z","shell.execute_reply.started":"2023-08-02T12:32:05.679204Z","shell.execute_reply":"2023-08-02T12:32:05.684035Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Dataset: hacker_news, Hacker News posts\n# A website focusing on computer science and cybersecurity news.\n# https://news.ycombinator.com/\n# BigQuery\n# ---------\n#     \\-- project\n#              \\-- bigquery-public-data\n#                           \\-- hacker_news\n\n# Construct a reference to the 'hacker_news' dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n#help(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:12:32.950272Z","iopub.execute_input":"2023-08-02T13:12:32.951598Z","iopub.status.idle":"2023-08-02T13:12:33.395579Z","shell.execute_reply.started":"2023-08-02T13:12:32.951541Z","shell.execute_reply":"2023-08-02T13:12:33.394258Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# List all the tables in the \"hacker_news\" dataset\ntables = list(client.list_tables(dataset))\n\n# Print names of all tables in the dataset (there are four!)\nfor table in tables:  \n    print(table.table_id)  # only one table - 'full'","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:14:57.626239Z","iopub.execute_input":"2023-08-02T13:14:57.626703Z","iopub.status.idle":"2023-08-02T13:14:57.932166Z","shell.execute_reply.started":"2023-08-02T13:14:57.626664Z","shell.execute_reply":"2023-08-02T13:14:57.931062Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"full\n","output_type":"stream"}]},{"cell_type":"code","source":"# Construct a reference ot the 'full' table\ntable_ref = dataset_ref.table('full')\n\n# API request - fetch table\ntable = client.get_table(table_ref)\n#table   # Table(TableReference(DatasetReference('bigquery-public-data', 'hacker_news'), 'full'))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:16:59.602580Z","iopub.execute_input":"2023-08-02T13:16:59.602952Z","iopub.status.idle":"2023-08-02T13:16:59.955522Z","shell.execute_reply.started":"2023-08-02T13:16:59.602923Z","shell.execute_reply":"2023-08-02T13:16:59.954219Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-media/learn/images/biYqbUB.png)","metadata":{}},{"cell_type":"markdown","source":"### Table schema   \nThe structure of table","metadata":{}},{"cell_type":"code","source":"# Print the info on all the columns in the 'full' tablre in the 'hacker_news\" dataset'\ntable.schema","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:19:54.617357Z","iopub.execute_input":"2023-08-02T13:19:54.617757Z","iopub.status.idle":"2023-08-02T13:19:54.626334Z","shell.execute_reply.started":"2023-08-02T13:19:54.617726Z","shell.execute_reply":"2023-08-02T13:19:54.625001Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[SchemaField('title', 'STRING', 'NULLABLE', 'Story title', (), None),\n SchemaField('url', 'STRING', 'NULLABLE', 'Story url', (), None),\n SchemaField('text', 'STRING', 'NULLABLE', 'Story or comment text', (), None),\n SchemaField('dead', 'BOOLEAN', 'NULLABLE', 'Is dead?', (), None),\n SchemaField('by', 'STRING', 'NULLABLE', \"The username of the item's author.\", (), None),\n SchemaField('score', 'INTEGER', 'NULLABLE', 'Story score', (), None),\n SchemaField('time', 'INTEGER', 'NULLABLE', 'Unix time', (), None),\n SchemaField('timestamp', 'TIMESTAMP', 'NULLABLE', 'Timestamp for the unix time', (), None),\n SchemaField('type', 'STRING', 'NULLABLE', 'Type of details (comment, comment_ranking, poll, story, job, pollopt)', (), None),\n SchemaField('id', 'INTEGER', 'NULLABLE', \"The item's unique id.\", (), None),\n SchemaField('parent', 'INTEGER', 'NULLABLE', 'Parent comment ID', (), None),\n SchemaField('descendants', 'INTEGER', 'NULLABLE', 'Number of story or poll descendants', (), None),\n SchemaField('ranking', 'INTEGER', 'NULLABLE', 'Comment ranking', (), None),\n SchemaField('deleted', 'BOOLEAN', 'NULLABLE', 'Is deleted?', (), None)]"},"metadata":{}}]},{"cell_type":"markdown","source":"SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())\n\nThis tells us:\n\nthe field (or column) is called by,\nthe data in this field is strings,\nNULL values are allowed, and\nit contains the usernames corresponding to each item's author.","metadata":{}},{"cell_type":"code","source":"# Preview the first five lines of the 'full' table\nrows = client.list_rows(table, max_results=12).to_dataframe() # to panda's df\nprint(type(rows))\nrows","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:24:59.779437Z","iopub.execute_input":"2023-08-02T13:24:59.779892Z","iopub.status.idle":"2023-08-02T13:25:00.821766Z","shell.execute_reply.started":"2023-08-02T13:24:59.779855Z","shell.execute_reply":"2023-08-02T13:25:00.820479Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   title   url                                               text  dead  \\\n0   None  None  I would rather just have wired earbuds, period...  None   \n1   None  None                                               DNS?  None   \n2   None  None  These benchmarks seem pretty good.  Filterable...  None   \n3   None  None  Oh really?<p>* Excel alone uses 86.1MB of priv...  None   \n4   None  None  These systems are useless.  Of the many flaws:...  None   \n5   None  None  <i>I don&#x27;t worry about the server</i> and...  None   \n6   None  None  Why do you take it as a given that the Secreta...  None   \n7   None  None  Let me know what you guys think so far and if ...  None   \n8   None  None  I often feel that the main result of this priv...  None   \n9   None  None  That is exactly why I generally prefer median-...  None   \n10  None  None  American farmers are anti-intellectual and rar...  None   \n11  None  None  &gt; For a 180lb male, it would take 4 drinks ...  None   \n\n              by  score        time                 timestamp     type  \\\n0          zeveb    NaN  1591717736 2020-06-09 15:48:56+00:00  comment   \n1            nly    NaN  1572810465 2019-11-03 19:47:45+00:00  comment   \n2         mrkeen    NaN  1591717727 2020-06-09 15:48:47+00:00  comment   \n3     oceanswave    NaN  1462987532 2016-05-11 17:25:32+00:00  comment   \n4         nyxxie    NaN  1572810473 2019-11-03 19:47:53+00:00  comment   \n5        dahfizz    NaN  1566231278 2019-08-19 16:14:38+00:00  comment   \n6      chatmasta    NaN  1425350594 2015-03-03 02:43:14+00:00  comment   \n7   augustin1989    NaN  1394076499 2014-03-06 03:28:19+00:00  comment   \n8      jaynetics    NaN  1572810482 2019-11-03 19:48:02+00:00  comment   \n9          bugra    NaN  1393290376 2014-02-25 01:06:16+00:00  comment   \n10     briandear    NaN  1572810489 2019-11-03 19:48:09+00:00  comment   \n11       eadmund    NaN  1572810497 2019-11-03 19:48:17+00:00  comment   \n\n          id    parent  descendants  ranking deleted  \n0   23467666  23456782          NaN      NaN    None  \n1   21436112  21435130          NaN      NaN    None  \n2   23467665  23467426          NaN      NaN    None  \n3   11677248  11676886          NaN      NaN    None  \n4   21436113  21435025          NaN      NaN    None  \n5   20739051  20738305          NaN      NaN    None  \n6    9135815   9135800          NaN      NaN    None  \n7    7351690   7351684          NaN      NaN    None  \n8   21436115  21435981          NaN      NaN    None  \n9    7294506   7293801          NaN      NaN    None  \n10  21436118  21436026          NaN      NaN    None  \n11  21436119  21434944          NaN      NaN    None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>text</th>\n      <th>dead</th>\n      <th>by</th>\n      <th>score</th>\n      <th>time</th>\n      <th>timestamp</th>\n      <th>type</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>None</td>\n      <td>I would rather just have wired earbuds, period...</td>\n      <td>None</td>\n      <td>zeveb</td>\n      <td>NaN</td>\n      <td>1591717736</td>\n      <td>2020-06-09 15:48:56+00:00</td>\n      <td>comment</td>\n      <td>23467666</td>\n      <td>23456782</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>None</td>\n      <td>DNS?</td>\n      <td>None</td>\n      <td>nly</td>\n      <td>NaN</td>\n      <td>1572810465</td>\n      <td>2019-11-03 19:47:45+00:00</td>\n      <td>comment</td>\n      <td>21436112</td>\n      <td>21435130</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n      <td>None</td>\n      <td>These benchmarks seem pretty good.  Filterable...</td>\n      <td>None</td>\n      <td>mrkeen</td>\n      <td>NaN</td>\n      <td>1591717727</td>\n      <td>2020-06-09 15:48:47+00:00</td>\n      <td>comment</td>\n      <td>23467665</td>\n      <td>23467426</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>None</td>\n      <td>Oh really?&lt;p&gt;* Excel alone uses 86.1MB of priv...</td>\n      <td>None</td>\n      <td>oceanswave</td>\n      <td>NaN</td>\n      <td>1462987532</td>\n      <td>2016-05-11 17:25:32+00:00</td>\n      <td>comment</td>\n      <td>11677248</td>\n      <td>11676886</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>None</td>\n      <td>These systems are useless.  Of the many flaws:...</td>\n      <td>None</td>\n      <td>nyxxie</td>\n      <td>NaN</td>\n      <td>1572810473</td>\n      <td>2019-11-03 19:47:53+00:00</td>\n      <td>comment</td>\n      <td>21436113</td>\n      <td>21435025</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>None</td>\n      <td>None</td>\n      <td>&lt;i&gt;I don&amp;#x27;t worry about the server&lt;/i&gt; and...</td>\n      <td>None</td>\n      <td>dahfizz</td>\n      <td>NaN</td>\n      <td>1566231278</td>\n      <td>2019-08-19 16:14:38+00:00</td>\n      <td>comment</td>\n      <td>20739051</td>\n      <td>20738305</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>None</td>\n      <td>None</td>\n      <td>Why do you take it as a given that the Secreta...</td>\n      <td>None</td>\n      <td>chatmasta</td>\n      <td>NaN</td>\n      <td>1425350594</td>\n      <td>2015-03-03 02:43:14+00:00</td>\n      <td>comment</td>\n      <td>9135815</td>\n      <td>9135800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>None</td>\n      <td>None</td>\n      <td>Let me know what you guys think so far and if ...</td>\n      <td>None</td>\n      <td>augustin1989</td>\n      <td>NaN</td>\n      <td>1394076499</td>\n      <td>2014-03-06 03:28:19+00:00</td>\n      <td>comment</td>\n      <td>7351690</td>\n      <td>7351684</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>None</td>\n      <td>None</td>\n      <td>I often feel that the main result of this priv...</td>\n      <td>None</td>\n      <td>jaynetics</td>\n      <td>NaN</td>\n      <td>1572810482</td>\n      <td>2019-11-03 19:48:02+00:00</td>\n      <td>comment</td>\n      <td>21436115</td>\n      <td>21435981</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>None</td>\n      <td>None</td>\n      <td>That is exactly why I generally prefer median-...</td>\n      <td>None</td>\n      <td>bugra</td>\n      <td>NaN</td>\n      <td>1393290376</td>\n      <td>2014-02-25 01:06:16+00:00</td>\n      <td>comment</td>\n      <td>7294506</td>\n      <td>7293801</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>None</td>\n      <td>None</td>\n      <td>American farmers are anti-intellectual and rar...</td>\n      <td>None</td>\n      <td>briandear</td>\n      <td>NaN</td>\n      <td>1572810489</td>\n      <td>2019-11-03 19:48:09+00:00</td>\n      <td>comment</td>\n      <td>21436118</td>\n      <td>21436026</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>None</td>\n      <td>None</td>\n      <td>&amp;gt; For a 180lb male, it would take 4 drinks ...</td>\n      <td>None</td>\n      <td>eadmund</td>\n      <td>NaN</td>\n      <td>1572810497</td>\n      <td>2019-11-03 19:48:17+00:00</td>\n      <td>comment</td>\n      <td>21436119</td>\n      <td>21434944</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Preview the first five entries in the \"title\" column of the \"full\" table\nclient.list_rows(table, selected_fields=table.schema[:1], max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:28:14.182679Z","iopub.execute_input":"2023-08-02T13:28:14.183059Z","iopub.status.idle":"2023-08-02T13:28:14.732635Z","shell.execute_reply.started":"2023-08-02T13:28:14.183029Z","shell.execute_reply":"2023-08-02T13:28:14.731486Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"  title\n0  None\n1  None\n2  None\n3  None\n4  None","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Exercise:    \n### Practice the commands to explore the structure of a dataset with crimes in the city of Chicago","metadata":{}},{"cell_type":"markdown","source":"**Fetch data from bigquery**     \n* dataset = chicago_crime\n* project = bigquery-public-data","metadata":{}},{"cell_type":"code","source":"# moudle, dataset access setup\n\nfrom google.cloud import bigquery\n\n# Create a 'Client' obj\nclient = bigquery.Client()\n\n# Construct a ref. to the dataset - 'chicago_crime'\ndataset_ref = client.dataset(\"chicago_crime\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:34:38.922842Z","iopub.execute_input":"2023-08-02T13:34:38.923602Z","iopub.status.idle":"2023-08-02T13:34:39.294547Z","shell.execute_reply.started":"2023-08-02T13:34:38.923566Z","shell.execute_reply":"2023-08-02T13:34:39.292849Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# count tables in the dataset\ntables = list(client.list_tables(dataset))\nnum_tables = len(tables)\nprint(num_tables)\n\n# print the table names\nfor table in tables:\n    print(table.table_id)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T13:43:21.109876Z","iopub.execute_input":"2023-08-02T13:43:21.110294Z","iopub.status.idle":"2023-08-02T13:43:21.408088Z","shell.execute_reply.started":"2023-08-02T13:43:21.110262Z","shell.execute_reply":"2023-08-02T13:43:21.406759Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"1\ncrime\n","output_type":"stream"}]},{"cell_type":"code","source":"# explore the table schema\n# How many columns in the crime table have TIMESTAMP data?\n\n# Construct a reference ot the 'full' table\ntable_id = \"crime\"\ntable_ref = dataset_ref.table(table_id)\n\n# API request - fetch table\ntable = client.get_table(table_ref)\nprint(\"Printing table schema item by item..\")\nfor field in table.schema:\n    print(field)\n#print(table.schema)\nprint(\"-\" * 80)\n\n# Counting columns with TIMESTAMP' field.\n# List with the field of interest\nfiled_to_seek = \"TIMESTAMP\"\nfields_of_interest = [item for item in table.schema if filed_to_seek in str(item)]\n\nprint(f\"{len(fields_of_interest)} column(s) found for \\\"{filed_to_seek}\\\" field, from the table \\\"{table.table_id}\\\".\")\nprint(fields_of_interest)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T14:59:34.460521Z","iopub.execute_input":"2023-08-02T14:59:34.460968Z","iopub.status.idle":"2023-08-02T14:59:34.782611Z","shell.execute_reply.started":"2023-08-02T14:59:34.460934Z","shell.execute_reply":"2023-08-02T14:59:34.781224Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Printing table schema item by item..\nSchemaField('unique_key', 'INTEGER', 'REQUIRED', None, (), None)\nSchemaField('case_number', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('date', 'TIMESTAMP', 'NULLABLE', None, (), None)\nSchemaField('block', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('iucr', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('primary_type', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('description', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('location_description', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('arrest', 'BOOLEAN', 'NULLABLE', None, (), None)\nSchemaField('domestic', 'BOOLEAN', 'NULLABLE', None, (), None)\nSchemaField('beat', 'INTEGER', 'NULLABLE', None, (), None)\nSchemaField('district', 'INTEGER', 'NULLABLE', None, (), None)\nSchemaField('ward', 'INTEGER', 'NULLABLE', None, (), None)\nSchemaField('community_area', 'INTEGER', 'NULLABLE', None, (), None)\nSchemaField('fbi_code', 'STRING', 'NULLABLE', None, (), None)\nSchemaField('x_coordinate', 'FLOAT', 'NULLABLE', None, (), None)\nSchemaField('y_coordinate', 'FLOAT', 'NULLABLE', None, (), None)\nSchemaField('year', 'INTEGER', 'NULLABLE', None, (), None)\nSchemaField('updated_on', 'TIMESTAMP', 'NULLABLE', None, (), None)\nSchemaField('latitude', 'FLOAT', 'NULLABLE', None, (), None)\nSchemaField('longitude', 'FLOAT', 'NULLABLE', None, (), None)\nSchemaField('location', 'STRING', 'NULLABLE', None, (), None)\n--------------------------------------------------------------------------------\n2 column(s) found for \"TIMESTAMP\" field, from the table \"crime\".\n[SchemaField('date', 'TIMESTAMP', 'NULLABLE', None, (), None), SchemaField('updated_on', 'TIMESTAMP', 'NULLABLE', None, (), None)]\n","output_type":"stream"}]},{"cell_type":"code","source":"# preview the table data in df.\nrows = client.list_rows(table, max_results=12).to_dataframe() # to panda's df\nrows\n\"\"\"\nThinking about the question above, there are a few columns that appear to have geographic data. Look at a few values (with the list_rows() command) to see if you can determine their relationship. Two columns will still be hard to interpret. But it should be obvious how the location column relates to latitude and longitude.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:17:25.780912Z","iopub.execute_input":"2023-08-02T15:17:25.781363Z","iopub.status.idle":"2023-08-02T15:17:26.512019Z","shell.execute_reply.started":"2023-08-02T15:17:25.781313Z","shell.execute_reply":"2023-08-02T15:17:26.510808Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"'\\nThinking about the question above, there are a few columns that appear to have geographic data. Look at a few values (with the list_rows() command) to see if you can determine their relationship. Two columns will still be hard to interpret. But it should be obvious how the location column relates to latitude and longitude.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# When mapping crime locations on map, what two fileds to pull out of the table?\nfields_for_plotting = ['latitude', 'longitude']\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:16:10.142120Z","iopub.execute_input":"2023-08-02T15:16:10.142544Z","iopub.status.idle":"2023-08-02T15:16:10.148327Z","shell.execute_reply.started":"2023-08-02T15:16:10.142510Z","shell.execute_reply":"2023-08-02T15:16:10.147026Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"## 2. Select, From & Where","metadata":{}},{"cell_type":"markdown","source":"### Example: What are all the U.S. cities in the OpenAQ dataset?   \ndataset: 'openAQ', Fighting air inequality through\nopen data. https://openaq.org/","metadata":{}},{"cell_type":"code","source":"# setup\n\n# 1. module for bigquery\nfrom google.cloud import bigquery\n\n# 'Client' obj\nclient = bigquery.Client()\n\n# Ref. to dataset - 'openaq'\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# List of all tables in the dataset\ntables = list(client.list_tables(dataset))\n\n# Print all table names in dataset\nfor table in tables:\n    print(table.table_id)  # The dataset contains only one table, called global_air_quality","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:27:24.506802Z","iopub.execute_input":"2023-08-02T15:27:24.507243Z","iopub.status.idle":"2023-08-02T15:27:25.197841Z","shell.execute_reply.started":"2023-08-02T15:27:24.507211Z","shell.execute_reply":"2023-08-02T15:27:25.196452Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\nglobal_air_quality\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ref. to the table - 'global_air_quality'\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API req. - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first 12 rows of the table in pandas df.\nclient.list_rows(table, max_results=12).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:29:30.475486Z","iopub.execute_input":"2023-08-02T15:29:30.475945Z","iopub.status.idle":"2023-08-02T15:29:31.370787Z","shell.execute_reply.started":"2023-08-02T15:29:30.475910Z","shell.execute_reply":"2023-08-02T15:29:31.369675Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"                         location          city country pollutant    value  \\\n0          Borówiec, ul. Drapałka      Borówiec      PL        bc  0.85217   \n1           Kraków, ul. Bulwarowa        Kraków      PL        bc  0.91284   \n2                 Płock, ul. Reja         Płock      PL        bc  1.41000   \n3         Elbląg, ul. Bażyńskiego        Elbląg      PL        bc  0.33607   \n4         Piastów, ul. Pułaskiego       Piastów      PL        bc  0.51000   \n5              Biała, ul. Kmicica         Biała      PL        bc  5.64000   \n6      Białystok, ul. Waszyngtona     Białystok      PL        bc  0.28000   \n7            Gdańsk, ul. Leczkowa        Gdańsk      PL        bc  0.37260   \n8       Zdzieszowice, ul. Piastów  Zdzieszowice      PL        bc  0.08659   \n9        Mielec, ul. Biernackiego        Mielec      PL        bc  0.49923   \n10  Legnica, al. Rzeczypospolitej       Legnica      PL        bc  0.73825   \n11          Łask, ul. Narutowicza          Łask      PL        bc  0.84000   \n\n                   timestamp   unit source_name  latitude  longitude  \\\n0  2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n1  2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n2  2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n3  2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n4  2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n5  2022-05-10 06:00:00+00:00  µg/m³        GIOS       1.0  52.602534   \n6  2022-05-09 14:00:00+00:00  µg/m³        GIOS       1.0  53.126689   \n7  2022-05-08 17:00:00+00:00  µg/m³        GIOS       1.0  54.380279   \n8  2022-05-15 19:00:00+00:00  µg/m³        GIOS       1.0  50.423533   \n9  2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  50.299128   \n10 2022-05-10 21:00:00+00:00  µg/m³        GIOS       1.0  51.204503   \n11 2022-04-19 04:00:00+00:00  µg/m³        GIOS       1.0  51.589261   \n\n    averaged_over_in_hours       location_geom  \n0                17.074114  POINT(52.276794 1)  \n1                20.053492  POINT(50.069308 1)  \n2                19.709791  POINT(52.550938 1)  \n3                19.410942  POINT(54.167847 1)  \n4                20.837489  POINT(52.191728 1)  \n5                19.645100  POINT(52.602534 1)  \n6                23.155869  POINT(53.126689 1)  \n7                18.620274  POINT(54.380279 1)  \n8                18.120739  POINT(50.423533 1)  \n9                21.440942  POINT(50.299128 1)  \n10               16.180513  POINT(51.204503 1)  \n11               19.131494  POINT(51.589261 1)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>city</th>\n      <th>country</th>\n      <th>pollutant</th>\n      <th>value</th>\n      <th>timestamp</th>\n      <th>unit</th>\n      <th>source_name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>averaged_over_in_hours</th>\n      <th>location_geom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Borówiec, ul. Drapałka</td>\n      <td>Borówiec</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.85217</td>\n      <td>2022-04-28 07:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.276794</td>\n      <td>17.074114</td>\n      <td>POINT(52.276794 1)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kraków, ul. Bulwarowa</td>\n      <td>Kraków</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.91284</td>\n      <td>2022-04-27 23:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.069308</td>\n      <td>20.053492</td>\n      <td>POINT(50.069308 1)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Płock, ul. Reja</td>\n      <td>Płock</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>1.41000</td>\n      <td>2022-03-30 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.550938</td>\n      <td>19.709791</td>\n      <td>POINT(52.550938 1)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elbląg, ul. Bażyńskiego</td>\n      <td>Elbląg</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.33607</td>\n      <td>2022-05-03 13:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>54.167847</td>\n      <td>19.410942</td>\n      <td>POINT(54.167847 1)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Piastów, ul. Pułaskiego</td>\n      <td>Piastów</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.51000</td>\n      <td>2022-05-11 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.191728</td>\n      <td>20.837489</td>\n      <td>POINT(52.191728 1)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Biała, ul. Kmicica</td>\n      <td>Biała</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>5.64000</td>\n      <td>2022-05-10 06:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.602534</td>\n      <td>19.645100</td>\n      <td>POINT(52.602534 1)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Białystok, ul. Waszyngtona</td>\n      <td>Białystok</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.28000</td>\n      <td>2022-05-09 14:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>53.126689</td>\n      <td>23.155869</td>\n      <td>POINT(53.126689 1)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Gdańsk, ul. Leczkowa</td>\n      <td>Gdańsk</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.37260</td>\n      <td>2022-05-08 17:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>54.380279</td>\n      <td>18.620274</td>\n      <td>POINT(54.380279 1)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Zdzieszowice, ul. Piastów</td>\n      <td>Zdzieszowice</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.08659</td>\n      <td>2022-05-15 19:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.423533</td>\n      <td>18.120739</td>\n      <td>POINT(50.423533 1)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Mielec, ul. Biernackiego</td>\n      <td>Mielec</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.49923</td>\n      <td>2022-05-11 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.299128</td>\n      <td>21.440942</td>\n      <td>POINT(50.299128 1)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Legnica, al. Rzeczypospolitej</td>\n      <td>Legnica</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.73825</td>\n      <td>2022-05-10 21:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>51.204503</td>\n      <td>16.180513</td>\n      <td>POINT(51.204503 1)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Łask, ul. Narutowicza</td>\n      <td>Łask</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.84000</td>\n      <td>2022-04-19 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>51.589261</td>\n      <td>19.131494</td>\n      <td>POINT(51.589261 1)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Prepare query to select all the items from the \"city\" column where the \"country\" column is 'US'\nquery = \"\"\"\n        SELECT city\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:36:36.572068Z","iopub.execute_input":"2023-08-02T15:36:36.572510Z","iopub.status.idle":"2023-08-02T15:36:36.578746Z","shell.execute_reply.started":"2023-08-02T15:36:36.572478Z","shell.execute_reply":"2023-08-02T15:36:36.576947Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# Submit the query to the dataset\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Set up the query\nquery_job = client.query(query)\n\n# Run the query, results to pandas df\nus_cities = query_job.to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:38:41.862368Z","iopub.execute_input":"2023-08-02T15:38:41.863213Z","iopub.status.idle":"2023-08-02T15:39:17.422396Z","shell.execute_reply.started":"2023-08-02T15:38:41.863177Z","shell.execute_reply":"2023-08-02T15:39:17.420515Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"code","source":"# check the results of the query in df\nus_cities","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:39:17.424434Z","iopub.execute_input":"2023-08-02T15:39:17.424825Z","iopub.status.idle":"2023-08-02T15:39:17.438764Z","shell.execute_reply.started":"2023-08-02T15:39:17.424795Z","shell.execute_reply":"2023-08-02T15:39:17.436744Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"                                             city\n0                                          HOWARD\n1                                          HOWARD\n2                                          HOWARD\n3                                          HOWARD\n4                                          HOWARD\n...                                           ...\n1421346  New York-Northern New Jersey-Long Island\n1421347  New York-Northern New Jersey-Long Island\n1421348  New York-Northern New Jersey-Long Island\n1421349  New York-Northern New Jersey-Long Island\n1421350  New York-Northern New Jersey-Long Island\n\n[1421351 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOWARD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOWARD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOWARD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOWARD</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOWARD</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1421346</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n    </tr>\n    <tr>\n      <th>1421347</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n    </tr>\n    <tr>\n      <th>1421348</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n    </tr>\n    <tr>\n      <th>1421349</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n    </tr>\n    <tr>\n      <th>1421350</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n    </tr>\n  </tbody>\n</table>\n<p>1421351 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# What five cities have the most measurements?\nus_cities.city.value_counts().head()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:40:20.727684Z","iopub.execute_input":"2023-08-02T15:40:20.728349Z","iopub.status.idle":"2023-08-02T15:40:20.921490Z","shell.execute_reply.started":"2023-08-02T15:40:20.728316Z","shell.execute_reply":"2023-08-02T15:40:20.920080Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"Phoenix-Mesa-Scottsdale                     39414\nLos Angeles-Long Beach-Santa Ana            27479\nRiverside-San Bernardino-Ontario            26887\nNew York-Northern New Jersey-Long Island    25417\nSan Francisco-Oakland-Fremont               22710\nName: city, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Some more queries\nquery = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n# Set up the query\nquery_job = client.query(query)\n\n# Run the query, results to pandas df\nentire_table = query_job.to_dataframe()\n\n# check the results of the query in df\nentire_table","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:43:01.282822Z","iopub.execute_input":"2023-08-02T15:43:01.283265Z","iopub.status.idle":"2023-08-02T15:46:58.689914Z","shell.execute_reply.started":"2023-08-02T15:43:01.283232Z","shell.execute_reply":"2023-08-02T15:46:58.688688Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"                     location                              city country  \\\n0               Laney College     San Francisco-Oakland-Fremont      US   \n1          Portland Near Road      Portland-Vancouver-Beaverton      US   \n2         San Jose - Knox Ave    San Jose-Sunnyvale-Santa Clara      US   \n3          McMillan Reservoir   Washington-Arlington-Alexandria      US   \n4        Howard County Near R                            HOWARD      US   \n...                       ...                               ...     ...   \n1421346  St. Paul-Harding H.S  Minneapolis-St. Paul-Bloomington      US   \n1421347  Gresham Centennial H                         MULTNOMAH      US   \n1421348               HICKORY          Hickory-Lenoir-Morganton      US   \n1421349  STILWELL CASTNET & N                             ADAIR      US   \n1421350               TRINITY            Detroit-Warren-Livonia      US   \n\n        pollutant  value                 timestamp   unit source_name  \\\n0              bc   0.48 2022-05-16 13:00:00+00:00  µg/m³      AirNow   \n1              bc   0.38 2022-05-14 07:00:00+00:00  µg/m³      AirNow   \n2              bc   0.28 2022-05-17 19:00:00+00:00  µg/m³      AirNow   \n3              bc   0.23 2022-05-23 02:00:00+00:00  µg/m³      AirNow   \n4              bc   0.80 2022-05-14 20:00:00+00:00  µg/m³      AirNow   \n...           ...    ...                       ...    ...         ...   \n1421346      pm25  13.00 2022-05-11 16:00:00+00:00  µg/m³      AirNow   \n1421347      pm25   1.70 2022-05-08 20:00:00+00:00  µg/m³      AirNow   \n1421348      pm25  12.00 2022-04-28 05:00:00+00:00  µg/m³      AirNow   \n1421349      pm25  16.00 2022-05-09 04:00:00+00:00  µg/m³      AirNow   \n1421350      pm25   5.90 2022-04-27 17:00:00+00:00  µg/m³      AirNow   \n\n         latitude  longitude  averaged_over_in_hours       location_geom  \n0             1.0  37.793624             -122.263376  POINT(37.793624 1)  \n1             1.0  45.399160             -122.745500   POINT(45.39916 1)  \n2             1.0  37.338202             -121.849892  POINT(37.338202 1)  \n3             1.0  38.921848              -77.013176  POINT(38.921848 1)  \n4             1.0  39.143197              -76.846192  POINT(39.143197 1)  \n...           ...        ...                     ...                 ...  \n1421346       1.0  44.959400              -93.035600    POINT(44.9594 1)  \n1421347       1.0  45.496200             -122.483400    POINT(45.4962 1)  \n1421348       1.0  35.728889              -81.365556  POINT(35.728889 1)  \n1421349       1.0  35.750599              -94.669701  POINT(35.750599 1)  \n1421350       1.0  42.295824              -83.129431  POINT(42.295824 1)  \n\n[1421351 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>city</th>\n      <th>country</th>\n      <th>pollutant</th>\n      <th>value</th>\n      <th>timestamp</th>\n      <th>unit</th>\n      <th>source_name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>averaged_over_in_hours</th>\n      <th>location_geom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Laney College</td>\n      <td>San Francisco-Oakland-Fremont</td>\n      <td>US</td>\n      <td>bc</td>\n      <td>0.48</td>\n      <td>2022-05-16 13:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>37.793624</td>\n      <td>-122.263376</td>\n      <td>POINT(37.793624 1)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Portland Near Road</td>\n      <td>Portland-Vancouver-Beaverton</td>\n      <td>US</td>\n      <td>bc</td>\n      <td>0.38</td>\n      <td>2022-05-14 07:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>45.399160</td>\n      <td>-122.745500</td>\n      <td>POINT(45.39916 1)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>San Jose - Knox Ave</td>\n      <td>San Jose-Sunnyvale-Santa Clara</td>\n      <td>US</td>\n      <td>bc</td>\n      <td>0.28</td>\n      <td>2022-05-17 19:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>37.338202</td>\n      <td>-121.849892</td>\n      <td>POINT(37.338202 1)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>McMillan Reservoir</td>\n      <td>Washington-Arlington-Alexandria</td>\n      <td>US</td>\n      <td>bc</td>\n      <td>0.23</td>\n      <td>2022-05-23 02:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>38.921848</td>\n      <td>-77.013176</td>\n      <td>POINT(38.921848 1)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Howard County Near R</td>\n      <td>HOWARD</td>\n      <td>US</td>\n      <td>bc</td>\n      <td>0.80</td>\n      <td>2022-05-14 20:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>39.143197</td>\n      <td>-76.846192</td>\n      <td>POINT(39.143197 1)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1421346</th>\n      <td>St. Paul-Harding H.S</td>\n      <td>Minneapolis-St. Paul-Bloomington</td>\n      <td>US</td>\n      <td>pm25</td>\n      <td>13.00</td>\n      <td>2022-05-11 16:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>44.959400</td>\n      <td>-93.035600</td>\n      <td>POINT(44.9594 1)</td>\n    </tr>\n    <tr>\n      <th>1421347</th>\n      <td>Gresham Centennial H</td>\n      <td>MULTNOMAH</td>\n      <td>US</td>\n      <td>pm25</td>\n      <td>1.70</td>\n      <td>2022-05-08 20:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>45.496200</td>\n      <td>-122.483400</td>\n      <td>POINT(45.4962 1)</td>\n    </tr>\n    <tr>\n      <th>1421348</th>\n      <td>HICKORY</td>\n      <td>Hickory-Lenoir-Morganton</td>\n      <td>US</td>\n      <td>pm25</td>\n      <td>12.00</td>\n      <td>2022-04-28 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>35.728889</td>\n      <td>-81.365556</td>\n      <td>POINT(35.728889 1)</td>\n    </tr>\n    <tr>\n      <th>1421349</th>\n      <td>STILWELL CASTNET &amp; N</td>\n      <td>ADAIR</td>\n      <td>US</td>\n      <td>pm25</td>\n      <td>16.00</td>\n      <td>2022-05-09 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>35.750599</td>\n      <td>-94.669701</td>\n      <td>POINT(35.750599 1)</td>\n    </tr>\n    <tr>\n      <th>1421350</th>\n      <td>TRINITY</td>\n      <td>Detroit-Warren-Livonia</td>\n      <td>US</td>\n      <td>pm25</td>\n      <td>5.90</td>\n      <td>2022-04-27 17:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>AirNow</td>\n      <td>1.0</td>\n      <td>42.295824</td>\n      <td>-83.129431</td>\n      <td>POINT(42.295824 1)</td>\n    </tr>\n  </tbody>\n</table>\n<p>1421351 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Some more queries\nquery = \"\"\"\n        SELECT city, country\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        \"\"\"\n# Set up the query\nquery_job = client.query(query)\n\n# Run the query, results to pandas df\ncity_country = query_job.to_dataframe()\n\n# check the results of the query in df\ncity_country","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:46:58.693083Z","iopub.execute_input":"2023-08-02T15:46:58.694142Z","iopub.status.idle":"2023-08-02T15:47:43.233211Z","shell.execute_reply.started":"2023-08-02T15:46:58.694093Z","shell.execute_reply":"2023-08-02T15:47:43.231881Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"                                             city country\n0                                          HOWARD      US\n1                                          HOWARD      US\n2                                          HOWARD      US\n3                                          HOWARD      US\n4                                          HOWARD      US\n...                                           ...     ...\n1421346  New York-Northern New Jersey-Long Island      US\n1421347  New York-Northern New Jersey-Long Island      US\n1421348  New York-Northern New Jersey-Long Island      US\n1421349  New York-Northern New Jersey-Long Island      US\n1421350  New York-Northern New Jersey-Long Island      US\n\n[1421351 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOWARD</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOWARD</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOWARD</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOWARD</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOWARD</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1421346</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1421347</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1421348</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1421349</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1421350</th>\n      <td>New York-Northern New Jersey-Long Island</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n<p>1421351 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Working witht big datasets    \nEach Kaggle user can scan 5TB every 30 days for free. Once you hit that limit, you'll have to wait for it to reset.\n\n* **Estimate query cost beforehand - query dry run**\n* **Limit the scan size - query safe run**","metadata":{}},{"cell_type":"code","source":"# Estimate query cost beforehand - query dry run\n\n# Query to get the score column from every row where the type column has value \"job\"\nquery = \"\"\"\n        SELECT score, title\n        FROM `bigquery-public-data.hacker_news.full`\n        WHERE type = \"job\" \n        \"\"\"\n\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job = client.query(query, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:50:55.613904Z","iopub.execute_input":"2023-08-02T15:50:55.614357Z","iopub.status.idle":"2023-08-02T15:50:56.159761Z","shell.execute_reply.started":"2023-08-02T15:50:55.614323Z","shell.execute_reply":"2023-08-02T15:50:56.158302Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"This query will process 553320240 bytes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Limit how much data you are willing to scan.\n\n# Only run the query if it's less than 1 GB\nONE_GB = 1000*1000*1000\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n\n# Set up the query (will only run if it's less than 1 GB)\nsafe_query_job = client.query(query, job_config=safe_config)\n\n# API request - try to run the query, and return a pandas DataFrame\njob_post_scores = safe_query_job.to_dataframe()\n\n# Print average score for job posts\njob_post_scores.score.mean()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:53:05.495080Z","iopub.execute_input":"2023-08-02T15:53:05.496120Z","iopub.status.idle":"2023-08-02T15:53:09.400837Z","shell.execute_reply.started":"2023-08-02T15:53:05.496071Z","shell.execute_reply":"2023-08-02T15:53:09.399559Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"1.7267060367454068"},"metadata":{}}]},{"cell_type":"code","source":"print(job_post_scores)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T15:53:36.942815Z","iopub.execute_input":"2023-08-02T15:53:36.943236Z","iopub.status.idle":"2023-08-02T15:53:36.953186Z","shell.execute_reply.started":"2023-08-02T15:53:36.943201Z","shell.execute_reply":"2023-08-02T15:53:36.951900Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"       score                                              title\n0        1.0  Full-stack Ruby on Rails engineer not afraid t...\n1        1.0  Come help us hack the Auto Industry - Dealer S...\n2        1.0  First full-stack web developer role @ Airware ...\n3        1.0  Generally Intelligent (YC S17) Is Hiring Syste...\n4        1.0  Factored Quality (YC W20) Is Hiring a Front En...\n...      ...                                                ...\n15843    8.0           Mixpanel (S09) hiring Software Engineers\n15844   15.0  Missed Work at a Startup but still want to wor...\n15845   19.0  Justin.tv is still hiring (join us in our beau...\n15846   29.0  Adioso (YC W09) needs FE developers to help ma...\n15847   32.0  Work at Socialcam and help the world share mob...\n\n[15848 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Exercise: Select, From & Where","metadata":{}},{"cell_type":"code","source":"# Fetches the global_air_quality table from the openaq dataset. \n# Preview the first twelve rows of the table.\n\n# Create a 'Clent' obj\nclient = bigquery.Client()\n\n# Ref. to 'openaq' dataset, project = 'bigquery-public-data'\ndataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n\n# API req. - fetch the datset\ndataset = client.get_dataset(dataset_ref)\n\n# Ref. to the table 'global_air_quality'\ntable_ref = dataset_ref.table(\"global_air_quality\")\n\n# API req. - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview in df\nclient.list_rows(table, max_results=12).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:23:38.071655Z","iopub.execute_input":"2023-08-02T16:23:38.072055Z","iopub.status.idle":"2023-08-02T16:23:39.439865Z","shell.execute_reply.started":"2023-08-02T16:23:38.072024Z","shell.execute_reply":"2023-08-02T16:23:39.438761Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"                         location          city country pollutant    value  \\\n0          Borówiec, ul. Drapałka      Borówiec      PL        bc  0.85217   \n1           Kraków, ul. Bulwarowa        Kraków      PL        bc  0.91284   \n2                 Płock, ul. Reja         Płock      PL        bc  1.41000   \n3         Elbląg, ul. Bażyńskiego        Elbląg      PL        bc  0.33607   \n4         Piastów, ul. Pułaskiego       Piastów      PL        bc  0.51000   \n5              Biała, ul. Kmicica         Biała      PL        bc  5.64000   \n6      Białystok, ul. Waszyngtona     Białystok      PL        bc  0.28000   \n7            Gdańsk, ul. Leczkowa        Gdańsk      PL        bc  0.37260   \n8       Zdzieszowice, ul. Piastów  Zdzieszowice      PL        bc  0.08659   \n9        Mielec, ul. Biernackiego        Mielec      PL        bc  0.49923   \n10  Legnica, al. Rzeczypospolitej       Legnica      PL        bc  0.73825   \n11          Łask, ul. Narutowicza          Łask      PL        bc  0.84000   \n\n                   timestamp   unit source_name  latitude  longitude  \\\n0  2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n1  2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n2  2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n3  2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n4  2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n5  2022-05-10 06:00:00+00:00  µg/m³        GIOS       1.0  52.602534   \n6  2022-05-09 14:00:00+00:00  µg/m³        GIOS       1.0  53.126689   \n7  2022-05-08 17:00:00+00:00  µg/m³        GIOS       1.0  54.380279   \n8  2022-05-15 19:00:00+00:00  µg/m³        GIOS       1.0  50.423533   \n9  2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  50.299128   \n10 2022-05-10 21:00:00+00:00  µg/m³        GIOS       1.0  51.204503   \n11 2022-04-19 04:00:00+00:00  µg/m³        GIOS       1.0  51.589261   \n\n    averaged_over_in_hours       location_geom  \n0                17.074114  POINT(52.276794 1)  \n1                20.053492  POINT(50.069308 1)  \n2                19.709791  POINT(52.550938 1)  \n3                19.410942  POINT(54.167847 1)  \n4                20.837489  POINT(52.191728 1)  \n5                19.645100  POINT(52.602534 1)  \n6                23.155869  POINT(53.126689 1)  \n7                18.620274  POINT(54.380279 1)  \n8                18.120739  POINT(50.423533 1)  \n9                21.440942  POINT(50.299128 1)  \n10               16.180513  POINT(51.204503 1)  \n11               19.131494  POINT(51.589261 1)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>city</th>\n      <th>country</th>\n      <th>pollutant</th>\n      <th>value</th>\n      <th>timestamp</th>\n      <th>unit</th>\n      <th>source_name</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>averaged_over_in_hours</th>\n      <th>location_geom</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Borówiec, ul. Drapałka</td>\n      <td>Borówiec</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.85217</td>\n      <td>2022-04-28 07:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.276794</td>\n      <td>17.074114</td>\n      <td>POINT(52.276794 1)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kraków, ul. Bulwarowa</td>\n      <td>Kraków</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.91284</td>\n      <td>2022-04-27 23:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.069308</td>\n      <td>20.053492</td>\n      <td>POINT(50.069308 1)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Płock, ul. Reja</td>\n      <td>Płock</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>1.41000</td>\n      <td>2022-03-30 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.550938</td>\n      <td>19.709791</td>\n      <td>POINT(52.550938 1)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Elbląg, ul. Bażyńskiego</td>\n      <td>Elbląg</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.33607</td>\n      <td>2022-05-03 13:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>54.167847</td>\n      <td>19.410942</td>\n      <td>POINT(54.167847 1)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Piastów, ul. Pułaskiego</td>\n      <td>Piastów</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.51000</td>\n      <td>2022-05-11 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.191728</td>\n      <td>20.837489</td>\n      <td>POINT(52.191728 1)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Biała, ul. Kmicica</td>\n      <td>Biała</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>5.64000</td>\n      <td>2022-05-10 06:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>52.602534</td>\n      <td>19.645100</td>\n      <td>POINT(52.602534 1)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Białystok, ul. Waszyngtona</td>\n      <td>Białystok</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.28000</td>\n      <td>2022-05-09 14:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>53.126689</td>\n      <td>23.155869</td>\n      <td>POINT(53.126689 1)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Gdańsk, ul. Leczkowa</td>\n      <td>Gdańsk</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.37260</td>\n      <td>2022-05-08 17:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>54.380279</td>\n      <td>18.620274</td>\n      <td>POINT(54.380279 1)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Zdzieszowice, ul. Piastów</td>\n      <td>Zdzieszowice</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.08659</td>\n      <td>2022-05-15 19:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.423533</td>\n      <td>18.120739</td>\n      <td>POINT(50.423533 1)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Mielec, ul. Biernackiego</td>\n      <td>Mielec</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.49923</td>\n      <td>2022-05-11 05:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>50.299128</td>\n      <td>21.440942</td>\n      <td>POINT(50.299128 1)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Legnica, al. Rzeczypospolitej</td>\n      <td>Legnica</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.73825</td>\n      <td>2022-05-10 21:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>51.204503</td>\n      <td>16.180513</td>\n      <td>POINT(51.204503 1)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Łask, ul. Narutowicza</td>\n      <td>Łask</td>\n      <td>PL</td>\n      <td>bc</td>\n      <td>0.84000</td>\n      <td>2022-04-19 04:00:00+00:00</td>\n      <td>µg/m³</td>\n      <td>GIOS</td>\n      <td>1.0</td>\n      <td>51.589261</td>\n      <td>19.131494</td>\n      <td>POINT(51.589261 1)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 1) Units of measurement\n# Which countries have reported pollution levels in units of \"ppm\"? \n\n# Set first_query to an SQL query that pulls the appropriate entries from the country column.\nfirst_query = \"\"\"\n        SELECT DISTINCT country\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE unit = \"ppm\"\n        \"\"\"\n# Set query scan limit to 10GB\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nfirst_query_job = client.query(first_query, job_config=safe_config)\n\n# API req. - run the query, return to pands of\nfirst_results = first_query_job.to_dataframe()\n\n# Prievew the df, first 12 rows\nprint(first_results.head(12))","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:35:25.831371Z","iopub.execute_input":"2023-08-02T16:35:25.831825Z","iopub.status.idle":"2023-08-02T16:35:27.286692Z","shell.execute_reply.started":"2023-08-02T16:35:25.831790Z","shell.execute_reply":"2023-08-02T16:35:27.285804Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"   country\n0       AR\n1       TW\n2       IL\n3       CO\n4       EC\n5       RW\n6       AU\n7       BR\n8       CA\n9       MX\n10      TH\n11      US\n","output_type":"stream"}]},{"cell_type":"code","source":"# 2) High air quality\n# Which pollution levels were reported to be exactly 0?\n# Set zero_pollution_query to select all columns of the rows where the value column is 0.\n# Set zero_pollution_results to a pandas DataFrame containing the query results.\n\n# Query to select all columns where pollution levels are exactly 0\nzero_pollution_query = \"\"\"\n        SELECT *\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE value = 0\n        \"\"\"\n# Set up the query with safe config\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(zero_pollution_query, job_config=safe_config)\n\n# API req. - run the query and return a pandas DataFrame\nzero_pollution_results = query_job.to_dataframe()\n\n# Preview df\nprint(zero_pollution_results.head())","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:41:03.208426Z","iopub.execute_input":"2023-08-02T16:41:03.208846Z","iopub.status.idle":"2023-08-02T16:41:36.187125Z","shell.execute_reply.started":"2023-08-02T16:41:03.208815Z","shell.execute_reply":"2023-08-02T16:41:36.185208Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"                       location      city country pollutant  value  \\\n0     Zielonka, Bory Tucholskie  Zielonka      PL        bc    0.0   \n1    Toruń, ul. Przy Kaszowniku     Toruń      PL        bc    0.0   \n2           Kielce, ul. Targowa    Kielce      PL        bc    0.0   \n3     Zielonka, Bory Tucholskie  Zielonka      PL        bc    0.0   \n4  Koszalin, ul. Armii Krajowej  Koszalin      PL        bc    0.0   \n\n                  timestamp   unit source_name  latitude  longitude  \\\n0 2022-04-29 14:00:00+00:00  µg/m³        GIOS       1.0  53.662136   \n1 2022-04-19 04:00:00+00:00  µg/m³        GIOS       1.0  53.017628   \n2 2022-05-07 17:00:00+00:00  µg/m³        GIOS       1.0  50.878998   \n3 2022-05-19 14:00:00+00:00  µg/m³        GIOS       1.0  53.662136   \n4 2022-05-12 20:00:00+00:00  µg/m³        GIOS       1.0  54.193986   \n\n   averaged_over_in_hours       location_geom  \n0               17.933986  POINT(53.662136 1)  \n1               18.612808  POINT(53.017628 1)  \n2               20.633692  POINT(50.878998 1)  \n3               17.933986  POINT(53.662136 1)  \n4               16.172544  POINT(54.193986 1)  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Group By, Having & Count    \nInteresting insights directly from queries like:    \n* How many of each kind of fruit has our store sold?\n* How many species of animal has the vet office treated?\n* **COUNT(), SUM(), AVG(), MIN(), MAX(), GROUP BY, GROUP BY HAVING**","metadata":{}},{"cell_type":"markdown","source":"### Example: Which Hacker News comments generated the most discussion?   \n* The Hacker News dataset contains information on stories and comments from the Hacker News social networking site.   \n* Will work with `full` table","metadata":{}},{"cell_type":"code","source":"# setup, connect , fetch\n\nfrom google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Print the list of tables in dataset\ntables = list(client.list_tables(dataset))\nfor table in tables:\n    print(table.table_id)\n\n# Construct a reference to the \"full\" table\ntable_ref = dataset_ref.table(\"full\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"comments\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T16:58:39.777350Z","iopub.execute_input":"2023-08-02T16:58:39.777824Z","iopub.status.idle":"2023-08-02T16:58:41.473540Z","shell.execute_reply.started":"2023-08-02T16:58:39.777789Z","shell.execute_reply":"2023-08-02T16:58:41.472155Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\nfull\n","output_type":"stream"},{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"  title   url                                               text  dead  \\\n0  None  None  I would rather just have wired earbuds, period...  None   \n1  None  None                                               DNS?  None   \n2  None  None  These benchmarks seem pretty good.  Filterable...  None   \n3  None  None  Oh really?<p>* Excel alone uses 86.1MB of priv...  None   \n4  None  None  These systems are useless.  Of the many flaws:...  None   \n\n           by  score        time                 timestamp     type        id  \\\n0       zeveb    NaN  1591717736 2020-06-09 15:48:56+00:00  comment  23467666   \n1         nly    NaN  1572810465 2019-11-03 19:47:45+00:00  comment  21436112   \n2      mrkeen    NaN  1591717727 2020-06-09 15:48:47+00:00  comment  23467665   \n3  oceanswave    NaN  1462987532 2016-05-11 17:25:32+00:00  comment  11677248   \n4      nyxxie    NaN  1572810473 2019-11-03 19:47:53+00:00  comment  21436113   \n\n     parent  descendants  ranking deleted  \n0  23456782          NaN      NaN    None  \n1  21435130          NaN      NaN    None  \n2  23467426          NaN      NaN    None  \n3  11676886          NaN      NaN    None  \n4  21435025          NaN      NaN    None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>text</th>\n      <th>dead</th>\n      <th>by</th>\n      <th>score</th>\n      <th>time</th>\n      <th>timestamp</th>\n      <th>type</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>None</td>\n      <td>None</td>\n      <td>I would rather just have wired earbuds, period...</td>\n      <td>None</td>\n      <td>zeveb</td>\n      <td>NaN</td>\n      <td>1591717736</td>\n      <td>2020-06-09 15:48:56+00:00</td>\n      <td>comment</td>\n      <td>23467666</td>\n      <td>23456782</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>None</td>\n      <td>DNS?</td>\n      <td>None</td>\n      <td>nly</td>\n      <td>NaN</td>\n      <td>1572810465</td>\n      <td>2019-11-03 19:47:45+00:00</td>\n      <td>comment</td>\n      <td>21436112</td>\n      <td>21435130</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>None</td>\n      <td>None</td>\n      <td>These benchmarks seem pretty good.  Filterable...</td>\n      <td>None</td>\n      <td>mrkeen</td>\n      <td>NaN</td>\n      <td>1591717727</td>\n      <td>2020-06-09 15:48:47+00:00</td>\n      <td>comment</td>\n      <td>23467665</td>\n      <td>23467426</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>None</td>\n      <td>Oh really?&lt;p&gt;* Excel alone uses 86.1MB of priv...</td>\n      <td>None</td>\n      <td>oceanswave</td>\n      <td>NaN</td>\n      <td>1462987532</td>\n      <td>2016-05-11 17:25:32+00:00</td>\n      <td>comment</td>\n      <td>11677248</td>\n      <td>11676886</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>None</td>\n      <td>These systems are useless.  Of the many flaws:...</td>\n      <td>None</td>\n      <td>nyxxie</td>\n      <td>NaN</td>\n      <td>1572810473</td>\n      <td>2019-11-03 19:47:53+00:00</td>\n      <td>comment</td>\n      <td>21436113</td>\n      <td>21435025</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's use the table to see which comments generated the most replies. Since:\n\nthe parent column indicates the comment that was replied to, and\nthe id column has the unique ID used to identify each comment,\nwe can GROUP BY the parent column and COUNT() the id column in order to figure out the number of comments that were made as responses to a specific comment. (This might not make sense immediately -- take your time here to ensure that everything is clear!)\n\nFurthermore, since we're only interested in popular comments, we'll look at comments with more than ten replies. So, we'll only return groups HAVING more than ten ID's.","metadata":{}},{"cell_type":"code","source":"# Query to select comments that received more than 10 replies\nquery_popular = \"\"\"\n        SELECT parent, COUNT(id)\n        FROM `bigquery-public-data.hacker_news.full`\n        GROUP BY parent\n        HAVING COUNT(id) > 10\n        \"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-02T17:05:34.567005Z","iopub.execute_input":"2023-08-02T17:05:34.567661Z","iopub.status.idle":"2023-08-02T17:05:34.572771Z","shell.execute_reply.started":"2023-08-02T17:05:34.567627Z","shell.execute_reply":"2023-08-02T17:05:34.571437Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# Set up the query with quata limited to 10 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query_popular, job_config=safe_config)\n\n# API request - run the query, and convert the results to a pandas DataFrame\npopular_comments = query_job.to_dataframe()\n\n# Print the first twelve rows of the DataFrame\npopular_comments.head(12)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T17:05:36.985170Z","iopub.execute_input":"2023-08-02T17:05:36.985588Z","iopub.status.idle":"2023-08-02T17:05:53.633573Z","shell.execute_reply.started":"2023-08-02T17:05:36.985555Z","shell.execute_reply":"2023-08-02T17:05:53.632444Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"        parent  f0_\n0   11266796.0   56\n1    9118977.0   48\n2   20584311.0  755\n3   28474997.0   52\n4   23734093.0   63\n5    7239333.0   43\n6   27335574.0  135\n7   17489934.0   77\n8   22577132.0  127\n9   24789379.0   89\n10  25992782.0  224\n11   3381822.0   46","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>f0_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11266796.0</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9118977.0</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20584311.0</td>\n      <td>755</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28474997.0</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23734093.0</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7239333.0</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>27335574.0</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>17489934.0</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22577132.0</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>24789379.0</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>25992782.0</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3381822.0</td>\n      <td>46</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"A couple hints to make your queries even better:\n\nThe column resulting from COUNT(id) was called f0__. That's not a very descriptive name. You can change the name by adding AS NumPosts after you specify the aggregation. This is called aliasing, and it will be covered in more detail in an upcoming lesson.\nIf you are ever unsure what to put inside the COUNT() function, you can do **COUNT(1)** to count the rows in each group. Most people find it especially readable, because we know it's not focusing on other columns. It also scans less data than if supplied column names (making it faster and using less of your data access quota).","metadata":{}},{"cell_type":"code","source":"# Improved version of earlier query, now with aliasing & improved readability\nquery_improved = \"\"\"\n                 SELECT parent, COUNT(1) AS NumPosts\n                 FROM `bigquery-public-data.hacker_news.full`\n                 GROUP BY parent\n                 HAVING COUNT(1) > 10\n                 \"\"\"\n\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(query_improved, job_config=safe_config)\n\n# API request - run the query, and convert the results to a pandas DataFrame\nimproved_df = query_job.to_dataframe()\n\n# Print the first five rows of the DataFrame\nimproved_df.head(12)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T17:08:29.344770Z","iopub.execute_input":"2023-08-02T17:08:29.345245Z","iopub.status.idle":"2023-08-02T17:08:45.058250Z","shell.execute_reply.started":"2023-08-02T17:08:29.345211Z","shell.execute_reply":"2023-08-02T17:08:45.057129Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"        parent  NumPosts\n0   33468611.0        49\n1    6761297.0       108\n2    9185356.0        83\n3   13682949.0       298\n4   31099186.0        81\n5   11340510.0       121\n6    1869046.0        55\n7   20990583.0       164\n8    5663157.0        45\n9   11456907.0        46\n10   8681040.0       493\n11   8881887.0        51","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parent</th>\n      <th>NumPosts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33468611.0</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6761297.0</td>\n      <td>108</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9185356.0</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13682949.0</td>\n      <td>298</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31099186.0</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11340510.0</td>\n      <td>121</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1869046.0</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20990583.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5663157.0</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>11456907.0</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>8681040.0</td>\n      <td>493</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>8881887.0</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Note on using GROUP BY**    \nNote that because it tells SQL how to apply aggregate functions (like COUNT()), it doesn't make sense to use GROUP BY without an aggregate function. Similarly, if you have any GROUP BY clause, then all variables must be passed to either a\n\n1. GROUP BY command, or\n1. an aggregation function.","metadata":{}},{"cell_type":"markdown","source":"### Exercise: Group By, Having & Count","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}