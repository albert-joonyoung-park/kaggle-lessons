{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-14T16:54:33.684406Z","iopub.execute_input":"2023-07-14T16:54:33.684894Z","iopub.status.idle":"2023-07-14T16:54:33.770421Z","shell.execute_reply.started":"2023-07-14T16:54:33.684850Z","shell.execute_reply":"2023-07-14T16:54:33.769638Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\n/kaggle/input/nflplaybyplay2009to2016/NFL Play by Play 2009-2016 (v3).csv\n/kaggle/input/nflplaybyplay2009to2016/NFL Play by Play 2009-2018 (v5).csv\n/kaggle/input/melbourne-housing-snapshot/melb_data.csv\n/kaggle/input/building-permit-applications-data/Building_Permits.csv\n/kaggle/input/building-permit-applications-data/DataDictionaryBuildingPermit.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"# modules to use\nimport numpy as np\nimport pandas as pd\n\n# read in the data\nnfl_data = pd.read_csv(\"/kaggle/input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\")\n\n# set seed for reproducibility\nnp.random.seed(0)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:33.771984Z","iopub.execute_input":"2023-07-14T16:54:33.772475Z","iopub.status.idle":"2023-07-14T16:54:41.143962Z","shell.execute_reply.started":"2023-07-14T16:54:33.772445Z","shell.execute_reply":"2023-07-14T16:54:41.142739Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/540425395.py:6: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n  nfl_data = pd.read_csv(\"/kaggle/input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# check some of the data for any visible missing data.\nprint(nfl_data.describe())\nnfl_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:41.145136Z","iopub.execute_input":"2023-07-14T16:54:41.146057Z","iopub.status.idle":"2023-07-14T16:54:41.974375Z","shell.execute_reply.started":"2023-07-14T16:54:41.146023Z","shell.execute_reply":"2023-07-14T16:54:41.973466Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"             GameID          Drive            qtr           down  \\\ncount  4.076880e+05  407688.000000  407688.000000  346534.000000   \nmean   2.013158e+09      12.316158       2.577412       2.002476   \nstd    2.572839e+06       7.149527       1.129750       1.006353   \nmin    2.009091e+09       1.000000       1.000000       1.000000   \n25%    2.011101e+09       6.000000       2.000000       1.000000   \n50%    2.013111e+09      12.000000       3.000000       2.000000   \n75%    2.015121e+09      18.000000       4.000000       3.000000   \nmax    2.017123e+09      35.000000       5.000000       4.000000   \n\n           TimeUnder       TimeSecs   PlayTimeDiff          yrdln  \\\ncount  407688.000000  407464.000000  407244.000000  406848.000000   \nmean        7.374200    1695.268944      20.576762      28.488327   \nstd         4.642388    1062.801012      17.969326      12.946471   \nmin         0.000000    -900.000000       0.000000       1.000000   \n25%         3.000000     778.000000       5.000000      20.000000   \n50%         7.000000    1800.000000      17.000000      30.000000   \n75%        11.000000    2585.000000      37.000000      39.000000   \nmax        15.000000    3600.000000     943.000000      50.000000   \n\n          yrdline100        ydstogo  ...         yacEPA    Home_WP_pre  \\\ncount  406848.000000  407688.000000  ...  159190.000000  382734.000000   \nmean       48.644081       7.309403  ...      -0.386086       0.534488   \nstd        25.070416       4.869987  ...       1.972715       0.285574   \nmin         1.000000       0.000000  ...     -14.000000       0.000000   \n25%        30.000000       3.000000  ...      -0.961115       0.325123   \n50%        49.000000       9.000000  ...       0.000000       0.531274   \n75%        70.000000      10.000000  ...       0.485508       0.769232   \nmax        99.000000      50.000000  ...       9.559834       1.000000   \n\n         Away_WP_pre   Home_WP_post   Away_WP_post       Win_Prob  \\\ncount  382734.000000  381101.000000  381101.000000  382679.000000   \nmean        0.465965       0.534791       0.465613       0.501320   \nstd         0.285629       0.287818       0.287867       0.287445   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.231411       0.321701       0.227694       0.276472   \n50%         0.469052       0.533609       0.466670       0.504470   \n75%         0.675530       0.772882       0.678833       0.725477   \nmax         1.000000       1.000000       1.000000       1.000000   \n\n                 WPA         airWPA         yacWPA         Season  \ncount  402147.000000  159187.000000  158926.000000  407688.000000  \nmean        0.002099       0.015135      -0.010480    2013.018985  \nstd         0.045363       0.056490       0.068139       2.576962  \nmin        -0.997214      -0.999881      -0.986673    2009.000000  \n25%        -0.014728      -0.011518      -0.018683    2011.000000  \n50%         0.000000       0.003441       0.000000    2013.000000  \n75%         0.014684       0.035792       0.011431    2015.000000  \nmax         0.994848       0.994848       1.000000    2017.000000  \n\n[8 rows x 64 columns]\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n0  2009-09-10  2009091000      1    1   NaN  15:00         15    3600.0   \n1  2009-09-10  2009091000      1    1   1.0  14:53         15    3593.0   \n2  2009-09-10  2009091000      1    1   2.0  14:16         15    3556.0   \n3  2009-09-10  2009091000      1    1   3.0  13:35         14    3515.0   \n4  2009-09-10  2009091000      1    1   4.0  13:27         14    3507.0   \n\n   PlayTimeDiff SideofField  ...    yacEPA  Home_WP_pre  Away_WP_pre  \\\n0           0.0         TEN  ...       NaN     0.485675     0.514325   \n1           7.0         PIT  ...  1.146076     0.546433     0.453567   \n2          37.0         PIT  ...       NaN     0.551088     0.448912   \n3          41.0         PIT  ... -5.031425     0.510793     0.489207   \n4           8.0         PIT  ...       NaN     0.461217     0.538783   \n\n   Home_WP_post  Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0      0.546433      0.453567  0.485675  0.060758       NaN       NaN    2009  \n1      0.551088      0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2      0.510793      0.489207  0.551088 -0.040295       NaN       NaN    2009  \n3      0.461217      0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4      0.558929      0.441071  0.461217  0.097712       NaN       NaN    2009  \n\n[5 rows x 102 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>15:00</td>\n      <td>15</td>\n      <td>3600.0</td>\n      <td>0.0</td>\n      <td>TEN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>14:53</td>\n      <td>15</td>\n      <td>3593.0</td>\n      <td>7.0</td>\n      <td>PIT</td>\n      <td>...</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>14:16</td>\n      <td>15</td>\n      <td>3556.0</td>\n      <td>37.0</td>\n      <td>PIT</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>13:35</td>\n      <td>14</td>\n      <td>3515.0</td>\n      <td>41.0</td>\n      <td>PIT</td>\n      <td>...</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>13:27</td>\n      <td>14</td>\n      <td>3507.0</td>\n      <td>8.0</td>\n      <td>PIT</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 102 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# identify missing values\ndf_rows_null = nfl_data.isnull()\nprint(df_rows_null) # data frame with null value marked with boolean True / False\ndf_rows_null.sum() # trick to get the count on null_value on columns - True = 1","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:41.976988Z","iopub.execute_input":"2023-07-14T16:54:41.977342Z","iopub.status.idle":"2023-07-14T16:54:43.954123Z","shell.execute_reply.started":"2023-07-14T16:54:41.977315Z","shell.execute_reply":"2023-07-14T16:54:43.953149Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"         Date  GameID  Drive    qtr   down   time  TimeUnder  TimeSecs  \\\n0       False   False  False  False   True  False      False     False   \n1       False   False  False  False  False  False      False     False   \n2       False   False  False  False  False  False      False     False   \n3       False   False  False  False  False  False      False     False   \n4       False   False  False  False  False  False      False     False   \n...       ...     ...    ...    ...    ...    ...        ...       ...   \n407683  False   False  False  False   True  False      False     False   \n407684  False   False  False  False  False  False      False     False   \n407685  False   False  False  False  False  False      False     False   \n407686  False   False  False  False  False  False      False     False   \n407687  False   False  False  False   True  False      False     False   \n\n        PlayTimeDiff  SideofField  ...  yacEPA  Home_WP_pre  Away_WP_pre  \\\n0              False        False  ...    True        False        False   \n1              False        False  ...   False        False        False   \n2              False        False  ...    True        False        False   \n3              False        False  ...   False        False        False   \n4              False        False  ...    True        False        False   \n...              ...          ...  ...     ...          ...          ...   \n407683         False        False  ...    True         True         True   \n407684         False        False  ...   False        False        False   \n407685         False        False  ...   False        False        False   \n407686         False        False  ...    True        False        False   \n407687         False        False  ...    True        False        False   \n\n        Home_WP_post  Away_WP_post  Win_Prob    WPA  airWPA  yacWPA  Season  \n0              False         False     False  False    True    True   False  \n1              False         False     False  False   False   False   False  \n2              False         False     False  False    True    True   False  \n3              False         False     False  False   False   False   False  \n4              False         False     False  False    True    True   False  \n...              ...           ...       ...    ...     ...     ...     ...  \n407683          True          True      True  False    True    True   False  \n407684         False         False     False  False   False   False   False  \n407685         False         False     False  False   False   False   False  \n407686         False         False     False  False    True    True   False  \n407687         False         False     False  False    True    True   False  \n\n[407688 rows x 102 columns]\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Date             0\nGameID           0\nDrive            0\nqtr              0\ndown         61154\n             ...  \nWin_Prob     25009\nWPA           5541\nairWPA      248501\nyacWPA      248762\nSeason           0\nLength: 102, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:**","metadata":{}},{"cell_type":"code","source":"# calculate the percentage of missing cells out of the total cells in the dataframe\n# create a function for reuse.\n\ndef get_null_info(df):\n    \"\"\"Receive a data frame, and return a DataFrame object contatininig:\n        1. Missing value percentage\n        2. Total number of values\n        3. Total number of missing values\"\"\"\n    total_cells = np.product(df.shape)\n    print(total_cells)\n    missing_cells = df.isnull().sum().sum()\n    print(missing_cells)\n    missing_pct = missing_cells / total_cells *100\n    print(missing_pct)\n    \n    data = { 'Missing value pct.': [ missing_pct ],\n            'Total number of values' : [total_cells],\n            'Total number of missing values' : [missing_cells] }\n    \n    return pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:43.955615Z","iopub.execute_input":"2023-07-14T16:54:43.955911Z","iopub.status.idle":"2023-07-14T16:54:43.962960Z","shell.execute_reply.started":"2023-07-14T16:54:43.955887Z","shell.execute_reply":"2023-07-14T16:54:43.961013Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"get_null_info(nfl_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:43.964630Z","iopub.execute_input":"2023-07-14T16:54:43.965339Z","iopub.status.idle":"2023-07-14T16:54:45.939221Z","shell.execute_reply.started":"2023-07-14T16:54:43.965284Z","shell.execute_reply":"2023-07-14T16:54:45.938326Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"41584176\n10342875\n24.87214126835169\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Missing value pct.  Total number of values  Total number of missing values\n0           24.872141                41584176                        10342875","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing value pct.</th>\n      <th>Total number of values</th>\n      <th>Total number of missing values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24.872141</td>\n      <td>41584176</td>\n      <td>10342875</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Figure out why the data is missing\n> **Is this value missing because it wasn't recorded or because it doesn't exist?**   \n\nThis is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to use your intution to figure out why the value is missing. One of the most important questions you can ask yourself to help figure this out is this:   \n\nIf a value is missing becuase it doesn't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probably do want to keep as NaN. On the other hand, if a value is missing because it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. This is called imputation, and we'll learn how to do it next! :)\n\n","metadata":{}},{"cell_type":"code","source":"# look at the # of missing values for columns\nmissing_value_count = nfl_data.isnull().sum()\nprint(missing_value_count)\n\n# looking at the first 10 columns only for now.\nmissing_value_count[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:45.940450Z","iopub.execute_input":"2023-07-14T16:54:45.940732Z","iopub.status.idle":"2023-07-14T16:54:47.901291Z","shell.execute_reply.started":"2023-07-14T16:54:45.940710Z","shell.execute_reply":"2023-07-14T16:54:47.899762Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Date             0\nGameID           0\nDrive            0\nqtr              0\ndown         61154\n             ...  \nWin_Prob     25009\nWPA           5541\nairWPA      248501\nyacWPA      248762\nSeason           0\nLength: 102, dtype: int64\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Date                0\nGameID              0\nDrive               0\nqtr                 0\ndown            61154\ntime              224\nTimeUnder           0\nTimeSecs          224\nPlayTimeDiff      444\nSideofField       528\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**Drop missing values**   \nIf you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I **don't generally recommend this approch for important projects!** It's usually worth it to **take the time to go through your data and really look at all the columns with missing values one-by-one** to really get to **know your dataset**.)","metadata":{}},{"cell_type":"code","source":"# remove all of the rows that contain a missing value\nnfl_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:47.903162Z","iopub.execute_input":"2023-07-14T16:54:47.903506Z","iopub.status.idle":"2023-07-14T16:54:49.883474Z","shell.execute_reply.started":"2023-07-14T16:54:47.903479Z","shell.execute_reply":"2023-07-14T16:54:49.882158Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Date, GameID, Drive, qtr, down, time, TimeUnder, TimeSecs, PlayTimeDiff, SideofField, yrdln, yrdline100, ydstogo, ydsnet, GoalToGo, FirstDown, posteam, DefensiveTeam, desc, PlayAttempted, Yards.Gained, sp, Touchdown, ExPointResult, TwoPointConv, DefTwoPoint, Safety, Onsidekick, PuntResult, PlayType, Passer, Passer_ID, PassAttempt, PassOutcome, PassLength, AirYards, YardsAfterCatch, QBHit, PassLocation, InterceptionThrown, Interceptor, Rusher, Rusher_ID, RushAttempt, RunLocation, RunGap, Receiver, Receiver_ID, Reception, ReturnResult, Returner, BlockingPlayer, Tackler1, Tackler2, FieldGoalResult, FieldGoalDistance, Fumble, RecFumbTeam, RecFumbPlayer, Sack, Challenge.Replay, ChalReplayResult, Accepted.Penalty, PenalizedTeam, PenaltyType, PenalizedPlayer, Penalty.Yards, PosTeamScore, DefTeamScore, ScoreDiff, AbsScoreDiff, HomeTeam, AwayTeam, Timeout_Indicator, Timeout_Team, posteam_timeouts_pre, HomeTimeouts_Remaining_Pre, AwayTimeouts_Remaining_Pre, HomeTimeouts_Remaining_Post, AwayTimeouts_Remaining_Post, No_Score_Prob, Opp_Field_Goal_Prob, Opp_Safety_Prob, Opp_Touchdown_Prob, Field_Goal_Prob, Safety_Prob, Touchdown_Prob, ExPoint_Prob, TwoPoint_Prob, ExpPts, EPA, airEPA, yacEPA, Home_WP_pre, Away_WP_pre, Home_WP_post, Away_WP_post, Win_Prob, WPA, airWPA, ...]\nIndex: []\n\n[0 rows x 102 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>down</th>\n      <th>time</th>\n      <th>TimeUnder</th>\n      <th>TimeSecs</th>\n      <th>PlayTimeDiff</th>\n      <th>SideofField</th>\n      <th>...</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 102 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Oh dear, it looks like that's **removed all our data!** 😱 This is **because every row in our dataset had at least one missing value**. We might have **better luck removing all the columns that have at least one missing value instead**.","metadata":{}},{"cell_type":"code","source":"# remove all columns with at least one missing value\ncolumns_with_na_dropped = nfl_data.dropna(axis=1)\ncolumns_with_na_dropped.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:49.885169Z","iopub.execute_input":"2023-07-14T16:54:49.885619Z","iopub.status.idle":"2023-07-14T16:54:51.899286Z","shell.execute_reply.started":"2023-07-14T16:54:49.885559Z","shell.execute_reply":"2023-07-14T16:54:51.898368Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         Date      GameID  Drive  qtr  TimeUnder  ydstogo  ydsnet  \\\n0  2009-09-10  2009091000      1    1         15        0       0   \n1  2009-09-10  2009091000      1    1         15       10       5   \n2  2009-09-10  2009091000      1    1         15        5       2   \n3  2009-09-10  2009091000      1    1         14        8       2   \n4  2009-09-10  2009091000      1    1         14        8       2   \n\n   PlayAttempted  Yards.Gained  sp  ...  Timeout_Indicator  Timeout_Team  \\\n0              1            39   0  ...                  0          None   \n1              1             5   0  ...                  0          None   \n2              1            -3   0  ...                  0          None   \n3              1             0   0  ...                  0          None   \n4              1             0   0  ...                  0          None   \n\n   posteam_timeouts_pre HomeTimeouts_Remaining_Pre AwayTimeouts_Remaining_Pre  \\\n0                     3                          3                          3   \n1                     3                          3                          3   \n2                     3                          3                          3   \n3                     3                          3                          3   \n4                     3                          3                          3   \n\n   HomeTimeouts_Remaining_Post  AwayTimeouts_Remaining_Post  ExPoint_Prob  \\\n0                            3                            3           0.0   \n1                            3                            3           0.0   \n2                            3                            3           0.0   \n3                            3                            3           0.0   \n4                            3                            3           0.0   \n\n   TwoPoint_Prob  Season  \n0            0.0    2009  \n1            0.0    2009  \n2            0.0    2009  \n3            0.0    2009  \n4            0.0    2009  \n\n[5 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>GameID</th>\n      <th>Drive</th>\n      <th>qtr</th>\n      <th>TimeUnder</th>\n      <th>ydstogo</th>\n      <th>ydsnet</th>\n      <th>PlayAttempted</th>\n      <th>Yards.Gained</th>\n      <th>sp</th>\n      <th>...</th>\n      <th>Timeout_Indicator</th>\n      <th>Timeout_Team</th>\n      <th>posteam_timeouts_pre</th>\n      <th>HomeTimeouts_Remaining_Pre</th>\n      <th>AwayTimeouts_Remaining_Pre</th>\n      <th>HomeTimeouts_Remaining_Post</th>\n      <th>AwayTimeouts_Remaining_Post</th>\n      <th>ExPoint_Prob</th>\n      <th>TwoPoint_Prob</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>10</td>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>15</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-09-10</td>\n      <td>2009091000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# how many columns did we loose after the drop? use dataframe.shape --> (#col, #row)\nprint(nfl_data.shape[1])\nprint(columns_with_na_dropped.shape[1])\n\n# 102 - 42 = 60 columns removed. removed all 'NaN's from the data\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:51.902776Z","iopub.execute_input":"2023-07-14T16:54:51.903040Z","iopub.status.idle":"2023-07-14T16:54:51.908480Z","shell.execute_reply.started":"2023-07-14T16:54:51.903019Z","shell.execute_reply":"2023-07-14T16:54:51.907313Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"102\n41\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Filling in missing values automatically**   \n\n1. Another option is to **try and fill in the missing values**.     \n2. For this next bit, I'm getting a **small sub-section of the NFL data** so that it will print well.","metadata":{}},{"cell_type":"code","source":"# to get a subset of data, slice the columns between 'EPA' and 'Season'\nsubset_nfl_data = nfl_data.loc[:, 'EPA':\"Season\"]  # all rows, 'EPA' ~ 'Season' columns\nsubset_nfl_data","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:51.910118Z","iopub.execute_input":"2023-07-14T16:54:51.910469Z","iopub.status.idle":"2023-07-14T16:54:51.950214Z","shell.execute_reply.started":"2023-07-14T16:54:51.910444Z","shell.execute_reply":"2023-07-14T16:54:51.949382Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474       NaN       NaN     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760       NaN       NaN     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796       NaN       NaN     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000       NaN       NaN          NaN          NaN           NaN   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000       NaN       NaN     0.030881     0.969119      0.000000   \n407687  0.000000       NaN       NaN     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758       NaN       NaN    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295       NaN       NaN    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712       NaN       NaN    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683           NaN       NaN  0.000000       NaN       NaN    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881       NaN       NaN    2017  \n407687      1.000000  0.999159  0.000000       NaN       NaN    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# decide what to fill the Nan with, here, let's fill them with 0\nsubset_nfl_data.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:51.951460Z","iopub.execute_input":"2023-07-14T16:54:51.951761Z","iopub.status.idle":"2023-07-14T16:54:51.996767Z","shell.execute_reply.started":"2023-07-14T16:54:51.951737Z","shell.execute_reply":"2023-07-14T16:54:51.995325Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474  0.000000  0.000000     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760  0.000000  0.000000     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796  0.000000  0.000000     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000  0.000000  0.000000     0.000000     0.000000      0.000000   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000  0.000000  0.000000     0.030881     0.969119      0.000000   \n407687  0.000000  0.000000  0.000000     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758  0.000000  0.000000    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295  0.000000  0.000000    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712  0.000000  0.000000    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683      0.000000  0.000000  0.000000  0.000000  0.000000    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881  0.000000  0.000000    2017  \n407687      1.000000  0.999159  0.000000  0.000000  0.000000    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Backfill**    \nAnother method to fill Nan, replace missing values with whatever **value comes directly after it in the same column**. (This makes a lot of sense for datasets **where the observations have some sort of logical order to them**.)","metadata":{}},{"cell_type":"code","source":"subset_nfl_data","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:51.998116Z","iopub.execute_input":"2023-07-14T16:54:51.998394Z","iopub.status.idle":"2023-07-14T16:54:52.018096Z","shell.execute_reply.started":"2023-07-14T16:54:51.998373Z","shell.execute_reply":"2023-07-14T16:54:52.017063Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474       NaN       NaN     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760       NaN       NaN     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796       NaN       NaN     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000       NaN       NaN          NaN          NaN           NaN   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000       NaN       NaN     0.030881     0.969119      0.000000   \n407687  0.000000       NaN       NaN     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758       NaN       NaN    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295       NaN       NaN    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712       NaN       NaN    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683           NaN       NaN  0.000000       NaN       NaN    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881       NaN       NaN    2017  \n407687      1.000000  0.999159  0.000000       NaN       NaN    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Fill the column value with NaN with the value that comes directly after it in the same column.\nsubset_nfl_data2 = subset_nfl_data.fillna(method='bfill', axis=0) # axis=0, along the rows, top to bottom\nsubset_nfl_data2","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:52.019964Z","iopub.execute_input":"2023-07-14T16:54:52.020331Z","iopub.status.idle":"2023-07-14T16:54:52.062720Z","shell.execute_reply.started":"2023-07-14T16:54:52.020302Z","shell.execute_reply":"2023-07-14T16:54:52.061081Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474 -1.068169  1.146076     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760  3.318841 -5.031425     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796 -0.343085  0.163935     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000       NaN       NaN     0.030881     0.969119      0.000000   \n407687  0.000000       NaN       NaN     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758 -0.032244  0.036899    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295  0.106663 -0.156239    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712 -0.010456  0.006029    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683      0.949522  0.080409  0.000000 -0.021795 -0.008136    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881       NaN       NaN    2017  \n407687      1.000000  0.999159  0.000000       NaN       NaN    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>-0.343085</td>\n      <td>0.163935</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>-0.010456</td>\n      <td>0.006029</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>0.000000</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# then, the rest of the NaN's with 0.\nsubset_nfl_data2.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:52.064707Z","iopub.execute_input":"2023-07-14T16:54:52.065114Z","iopub.status.idle":"2023-07-14T16:54:52.096938Z","shell.execute_reply.started":"2023-07-14T16:54:52.065083Z","shell.execute_reply":"2023-07-14T16:54:52.095902Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474 -1.068169  1.146076     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760  3.318841 -5.031425     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796 -0.343085  0.163935     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000  0.000000  0.000000     0.030881     0.969119      0.000000   \n407687  0.000000  0.000000  0.000000     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758 -0.032244  0.036899    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295  0.106663 -0.156239    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712 -0.010456  0.006029    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683      0.949522  0.080409  0.000000 -0.021795 -0.008136    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881  0.000000  0.000000    2017  \n407687      1.000000  0.999159  0.000000  0.000000  0.000000    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>-0.343085</td>\n      <td>0.163935</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>-0.010456</td>\n      <td>0.006029</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>0.000000</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# The above fillna() operations can be done in one line.\nsubset_nfl_data.fillna(method='bfill', axis=0).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:52.098016Z","iopub.execute_input":"2023-07-14T16:54:52.098273Z","iopub.status.idle":"2023-07-14T16:54:52.147556Z","shell.execute_reply.started":"2023-07-14T16:54:52.098252Z","shell.execute_reply":"2023-07-14T16:54:52.146894Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             EPA    airEPA    yacEPA  Home_WP_pre  Away_WP_pre  Home_WP_post  \\\n0       2.014474 -1.068169  1.146076     0.485675     0.514325      0.546433   \n1       0.077907 -1.068169  1.146076     0.546433     0.453567      0.551088   \n2      -1.402760  3.318841 -5.031425     0.551088     0.448912      0.510793   \n3      -1.712583  3.318841 -5.031425     0.510793     0.489207      0.461217   \n4       2.097796 -0.343085  0.163935     0.461217     0.538783      0.558929   \n...          ...       ...       ...          ...          ...           ...   \n407683  0.000000  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407684 -0.340818  0.056697 -0.397515     0.080409     0.919591      0.050478   \n407685  0.139913 -2.317201  2.457114     0.050478     0.949522      0.030881   \n407686  0.000000  0.000000  0.000000     0.030881     0.969119      0.000000   \n407687  0.000000  0.000000  0.000000     0.000000     1.000000      0.000000   \n\n        Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  Season  \n0           0.453567  0.485675  0.060758 -0.032244  0.036899    2009  \n1           0.448912  0.546433  0.004655 -0.032244  0.036899    2009  \n2           0.489207  0.551088 -0.040295  0.106663 -0.156239    2009  \n3           0.538783  0.510793 -0.049576  0.106663 -0.156239    2009  \n4           0.441071  0.461217  0.097712 -0.010456  0.006029    2009  \n...              ...       ...       ...       ...       ...     ...  \n407683      0.949522  0.080409  0.000000 -0.021795 -0.008136    2017  \n407684      0.949522  0.080409 -0.029931 -0.021795 -0.008136    2017  \n407685      0.969119  0.050478 -0.019597 -0.030603  0.011006    2017  \n407686      1.000000  0.969119  0.030881  0.000000  0.000000    2017  \n407687      1.000000  0.999159  0.000000  0.000000  0.000000    2017  \n\n[407688 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EPA</th>\n      <th>airEPA</th>\n      <th>yacEPA</th>\n      <th>Home_WP_pre</th>\n      <th>Away_WP_pre</th>\n      <th>Home_WP_post</th>\n      <th>Away_WP_post</th>\n      <th>Win_Prob</th>\n      <th>WPA</th>\n      <th>airWPA</th>\n      <th>yacWPA</th>\n      <th>Season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.014474</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.485675</td>\n      <td>0.514325</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.485675</td>\n      <td>0.060758</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.077907</td>\n      <td>-1.068169</td>\n      <td>1.146076</td>\n      <td>0.546433</td>\n      <td>0.453567</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.546433</td>\n      <td>0.004655</td>\n      <td>-0.032244</td>\n      <td>0.036899</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.402760</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.551088</td>\n      <td>0.448912</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.551088</td>\n      <td>-0.040295</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.712583</td>\n      <td>3.318841</td>\n      <td>-5.031425</td>\n      <td>0.510793</td>\n      <td>0.489207</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.510793</td>\n      <td>-0.049576</td>\n      <td>0.106663</td>\n      <td>-0.156239</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.097796</td>\n      <td>-0.343085</td>\n      <td>0.163935</td>\n      <td>0.461217</td>\n      <td>0.538783</td>\n      <td>0.558929</td>\n      <td>0.441071</td>\n      <td>0.461217</td>\n      <td>0.097712</td>\n      <td>-0.010456</td>\n      <td>0.006029</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>407683</th>\n      <td>0.000000</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>0.000000</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407684</th>\n      <td>-0.340818</td>\n      <td>0.056697</td>\n      <td>-0.397515</td>\n      <td>0.080409</td>\n      <td>0.919591</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.080409</td>\n      <td>-0.029931</td>\n      <td>-0.021795</td>\n      <td>-0.008136</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407685</th>\n      <td>0.139913</td>\n      <td>-2.317201</td>\n      <td>2.457114</td>\n      <td>0.050478</td>\n      <td>0.949522</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.050478</td>\n      <td>-0.019597</td>\n      <td>-0.030603</td>\n      <td>0.011006</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407686</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030881</td>\n      <td>0.969119</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.969119</td>\n      <td>0.030881</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>407687</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.999159</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2017</td>\n    </tr>\n  </tbody>\n</table>\n<p>407688 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Handling missing values    \nExercise 1. Load the data and take a look at the data**    \n/kaggle/input/building-permit-applications-data/Building_Permits.csv\nSan Francisco building permits data","metadata":{}},{"cell_type":"code","source":"# load required modules\nimport numpy as np\nimport pandas as pd\n\n# read in the data\nsf_permits = pd.read_csv(\"/kaggle/input/building-permit-applications-data/Building_Permits.csv\")\n\n# set seed for reproducibility - 0 \nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:52.148586Z","iopub.execute_input":"2023-07-14T16:54:52.149161Z","iopub.status.idle":"2023-07-14T16:54:54.254915Z","shell.execute_reply.started":"2023-07-14T16:54:52.149128Z","shell.execute_reply":"2023-07-14T16:54:54.253491Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/2209524639.py:6: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n  sf_permits = pd.read_csv(\"/kaggle/input/building-permit-applications-data/Building_Permits.csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# inspect the first 5 rows\nsf_permits.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:54.256463Z","iopub.execute_input":"2023-07-14T16:54:54.256917Z","iopub.status.idle":"2023-07-14T16:54:54.284059Z","shell.execute_reply.started":"2023-07-14T16:54:54.256880Z","shell.execute_reply":"2023-07-14T16:54:54.283071Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  Permit Number  Permit Type            Permit Type Definition  \\\n0  201505065519            4                      sign - erect   \n1  201604195146            4                      sign - erect   \n2  201605278609            3  additions alterations or repairs   \n3  201611072166            8            otc alterations permit   \n4  201611283529            6                       demolitions   \n\n  Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n0           05/06/2015  0326  023            140                  NaN   \n1           04/19/2016  0306  007            440                  NaN   \n2           05/27/2016  0595  203           1647                  NaN   \n3           11/07/2016  0156  011           1230                  NaN   \n4           11/28/2016  0342  001            950                  NaN   \n\n  Street Name Street Suffix  ...  Existing Construction Type  \\\n0       Ellis            St  ...                         3.0   \n1       Geary            St  ...                         3.0   \n2     Pacific            Av  ...                         1.0   \n3     Pacific            Av  ...                         5.0   \n4      Market            St  ...                         3.0   \n\n  Existing Construction Type Description Proposed Construction Type  \\\n0                          constr type 3                        NaN   \n1                          constr type 3                        NaN   \n2                          constr type 1                        1.0   \n3                         wood frame (5)                        5.0   \n4                          constr type 3                        NaN   \n\n  Proposed Construction Type Description Site Permit Supervisor District  \\\n0                                    NaN         NaN                 3.0   \n1                                    NaN         NaN                 3.0   \n2                          constr type 1         NaN                 3.0   \n3                         wood frame (5)         NaN                 3.0   \n4                                    NaN         NaN                 6.0   \n\n  Neighborhoods - Analysis Boundaries  Zipcode  \\\n0                          Tenderloin  94102.0   \n1                          Tenderloin  94102.0   \n2                        Russian Hill  94109.0   \n3                            Nob Hill  94109.0   \n4                          Tenderloin  94102.0   \n\n                                    Location      Record ID  \n0  (37.785719256680785, -122.40852313194863)  1380611233945  \n1   (37.78733980600732, -122.41063199757738)  1420164406718  \n2    (37.7946573324287, -122.42232562979227)  1424856504716  \n3   (37.79595867909168, -122.41557405519474)  1443574295566  \n4   (37.78315261897309, -122.40950883997789)   144548169992  \n\n[5 rows x 43 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>...</th>\n      <th>Existing Construction Type</th>\n      <th>Existing Construction Type Description</th>\n      <th>Proposed Construction Type</th>\n      <th>Proposed Construction Type Description</th>\n      <th>Site Permit</th>\n      <th>Supervisor District</th>\n      <th>Neighborhoods - Analysis Boundaries</th>\n      <th>Zipcode</th>\n      <th>Location</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201505065519</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>05/06/2015</td>\n      <td>0326</td>\n      <td>023</td>\n      <td>140</td>\n      <td>NaN</td>\n      <td>Ellis</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.785719256680785, -122.40852313194863)</td>\n      <td>1380611233945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>201604195146</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>04/19/2016</td>\n      <td>0306</td>\n      <td>007</td>\n      <td>440</td>\n      <td>NaN</td>\n      <td>Geary</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.78733980600732, -122.41063199757738)</td>\n      <td>1420164406718</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>201605278609</td>\n      <td>3</td>\n      <td>additions alterations or repairs</td>\n      <td>05/27/2016</td>\n      <td>0595</td>\n      <td>203</td>\n      <td>1647</td>\n      <td>NaN</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Russian Hill</td>\n      <td>94109.0</td>\n      <td>(37.7946573324287, -122.42232562979227)</td>\n      <td>1424856504716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>201611072166</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>11/07/2016</td>\n      <td>0156</td>\n      <td>011</td>\n      <td>1230</td>\n      <td>NaN</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Nob Hill</td>\n      <td>94109.0</td>\n      <td>(37.79595867909168, -122.41557405519474)</td>\n      <td>1443574295566</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>201611283529</td>\n      <td>6</td>\n      <td>demolitions</td>\n      <td>11/28/2016</td>\n      <td>0342</td>\n      <td>001</td>\n      <td>950</td>\n      <td>NaN</td>\n      <td>Market</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.78315261897309, -122.40950883997789)</td>\n      <td>144548169992</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 43 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Exercise 2. How many missing data points do we have?**","metadata":{}},{"cell_type":"code","source":"# get the number of missing data points per column\nmissing_values_count = sf_permits.isnull().sum()\n\n# how many total missing values do we have?\ntotal_cells = np.product(sf_permits.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that is missing\npercent_missing = (total_missing/total_cells) * 100\npercent_missing","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:54.285154Z","iopub.execute_input":"2023-07-14T16:54:54.285434Z","iopub.status.idle":"2023-07-14T16:54:55.043696Z","shell.execute_reply.started":"2023-07-14T16:54:54.285408Z","shell.execute_reply":"2023-07-14T16:54:55.042803Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"26.26002315058403"},"metadata":{}}]},{"cell_type":"markdown","source":"**Exercise 3. Figure out why the data is missing?**","metadata":{}},{"cell_type":"markdown","source":"Look at the columns \"**Street Number Suffix**\" and \"**Zipcode**\" from the San Francisco Building Permits dataset. Both of these contain missing values.      \n\n1. Which, if either, are missing because they don't exist?\n1. Which, if either, are missing because they weren't recorded?\n\n> If a value in the \"Street Number Suffix\" column is missing, it is likely because it does not exist. If a value in the \"Zipcode\" column is missing, it was not recorded.","metadata":{}},{"cell_type":"markdown","source":"**Exercise 4.**   \n**Drop missing values: rows**","metadata":{}},{"cell_type":"markdown","source":"If you removed all of the rows of sf_permits with missing values, how many rows are left?","metadata":{}},{"cell_type":"code","source":"sf_permits.dropna().shape #(0, 43) 0 rows x 43 cols\nsf_permits.dropna().shape[0] # 0","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:55.045004Z","iopub.execute_input":"2023-07-14T16:54:55.045286Z","iopub.status.idle":"2023-07-14T16:54:56.496342Z","shell.execute_reply.started":"2023-07-14T16:54:55.045262Z","shell.execute_reply":"2023-07-14T16:54:56.495106Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"**Drop missing values: columns**","metadata":{}},{"cell_type":"markdown","source":"Try removing all the columns with empty values.","metadata":{}},{"cell_type":"code","source":"# remove all columns with at least one missing value\nsf_permits_with_na_dropped = sf_permits.dropna(axis=1)\n\n# calculate number of dropped columns\ncols_in_original_dataset = sf_permits.shape[1]\ncols_in_na_dropped = sf_permits_with_na_dropped.shape[1]\ndropped_columns = cols_in_original_dataset - cols_in_na_dropped\n\nsf_permits_with_na_dropped\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:56.498262Z","iopub.execute_input":"2023-07-14T16:54:56.498720Z","iopub.status.idle":"2023-07-14T16:54:57.232863Z","shell.execute_reply.started":"2023-07-14T16:54:56.498672Z","shell.execute_reply":"2023-07-14T16:54:57.231450Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"       Permit Number  Permit Type            Permit Type Definition  \\\n0       201505065519            4                      sign - erect   \n1       201604195146            4                      sign - erect   \n2       201605278609            3  additions alterations or repairs   \n3       201611072166            8            otc alterations permit   \n4       201611283529            6                       demolitions   \n...              ...          ...                               ...   \n198895       M862628            8            otc alterations permit   \n198896  201712055595            8            otc alterations permit   \n198897       M863507            8            otc alterations permit   \n198898       M863747            8            otc alterations permit   \n198899       M864287            8            otc alterations permit   \n\n       Permit Creation Date Block   Lot  Street Number Street Name  \\\n0                05/06/2015  0326   023            140       Ellis   \n1                04/19/2016  0306   007            440       Geary   \n2                05/27/2016  0595   203           1647     Pacific   \n3                11/07/2016  0156   011           1230     Pacific   \n4                11/28/2016  0342   001            950      Market   \n...                     ...   ...   ...            ...         ...   \n198895           12/05/2017  0113  017A           1228  Montgomery   \n198896           12/05/2017  0271   014            580        Bush   \n198897           12/06/2017  4318   019           1568     Indiana   \n198898           12/06/2017  0298   029            795      Sutter   \n198899           12/07/2017  0160   006            838     Pacific   \n\n       Current Status Current Status Date  Filed Date      Record ID  \n0             expired          12/21/2017  05/06/2015  1380611233945  \n1              issued          08/03/2017  04/19/2016  1420164406718  \n2           withdrawn          09/26/2017  05/27/2016  1424856504716  \n3            complete          07/24/2017  11/07/2016  1443574295566  \n4              issued          12/01/2017  11/28/2016   144548169992  \n...               ...                 ...         ...            ...  \n198895         issued          12/05/2017  12/05/2017  1489337276729  \n198896         issued          12/06/2017  12/05/2017  1489462354993  \n198897         issued          12/06/2017  12/06/2017  1489539379952  \n198898         issued          12/06/2017  12/06/2017  1489608233656  \n198899         issued          12/07/2017  12/07/2017  1489796283803  \n\n[198900 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Name</th>\n      <th>Current Status</th>\n      <th>Current Status Date</th>\n      <th>Filed Date</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201505065519</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>05/06/2015</td>\n      <td>0326</td>\n      <td>023</td>\n      <td>140</td>\n      <td>Ellis</td>\n      <td>expired</td>\n      <td>12/21/2017</td>\n      <td>05/06/2015</td>\n      <td>1380611233945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>201604195146</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>04/19/2016</td>\n      <td>0306</td>\n      <td>007</td>\n      <td>440</td>\n      <td>Geary</td>\n      <td>issued</td>\n      <td>08/03/2017</td>\n      <td>04/19/2016</td>\n      <td>1420164406718</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>201605278609</td>\n      <td>3</td>\n      <td>additions alterations or repairs</td>\n      <td>05/27/2016</td>\n      <td>0595</td>\n      <td>203</td>\n      <td>1647</td>\n      <td>Pacific</td>\n      <td>withdrawn</td>\n      <td>09/26/2017</td>\n      <td>05/27/2016</td>\n      <td>1424856504716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>201611072166</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>11/07/2016</td>\n      <td>0156</td>\n      <td>011</td>\n      <td>1230</td>\n      <td>Pacific</td>\n      <td>complete</td>\n      <td>07/24/2017</td>\n      <td>11/07/2016</td>\n      <td>1443574295566</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>201611283529</td>\n      <td>6</td>\n      <td>demolitions</td>\n      <td>11/28/2016</td>\n      <td>0342</td>\n      <td>001</td>\n      <td>950</td>\n      <td>Market</td>\n      <td>issued</td>\n      <td>12/01/2017</td>\n      <td>11/28/2016</td>\n      <td>144548169992</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>198895</th>\n      <td>M862628</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/05/2017</td>\n      <td>0113</td>\n      <td>017A</td>\n      <td>1228</td>\n      <td>Montgomery</td>\n      <td>issued</td>\n      <td>12/05/2017</td>\n      <td>12/05/2017</td>\n      <td>1489337276729</td>\n    </tr>\n    <tr>\n      <th>198896</th>\n      <td>201712055595</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/05/2017</td>\n      <td>0271</td>\n      <td>014</td>\n      <td>580</td>\n      <td>Bush</td>\n      <td>issued</td>\n      <td>12/06/2017</td>\n      <td>12/05/2017</td>\n      <td>1489462354993</td>\n    </tr>\n    <tr>\n      <th>198897</th>\n      <td>M863507</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/06/2017</td>\n      <td>4318</td>\n      <td>019</td>\n      <td>1568</td>\n      <td>Indiana</td>\n      <td>issued</td>\n      <td>12/06/2017</td>\n      <td>12/06/2017</td>\n      <td>1489539379952</td>\n    </tr>\n    <tr>\n      <th>198898</th>\n      <td>M863747</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/06/2017</td>\n      <td>0298</td>\n      <td>029</td>\n      <td>795</td>\n      <td>Sutter</td>\n      <td>issued</td>\n      <td>12/06/2017</td>\n      <td>12/06/2017</td>\n      <td>1489608233656</td>\n    </tr>\n    <tr>\n      <th>198899</th>\n      <td>M864287</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/07/2017</td>\n      <td>0160</td>\n      <td>006</td>\n      <td>838</td>\n      <td>Pacific</td>\n      <td>issued</td>\n      <td>12/07/2017</td>\n      <td>12/07/2017</td>\n      <td>1489796283803</td>\n    </tr>\n  </tbody>\n</table>\n<p>198900 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Fill in missing values automatically**","metadata":{}},{"cell_type":"markdown","source":"Try replacing all the NaN's in the sf_permits data with the one that comes directly after it and then replacing any remaining NaN's with 0. Set the result to a new DataFrame sf_permits_with_na_imputed.","metadata":{}},{"cell_type":"code","source":"sf_permits_with_na_imputed = sf_permits.fillna(method=\"bfill\", axis=0).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:57.234064Z","iopub.execute_input":"2023-07-14T16:54:57.234364Z","iopub.status.idle":"2023-07-14T16:54:58.909891Z","shell.execute_reply.started":"2023-07-14T16:54:57.234336Z","shell.execute_reply":"2023-07-14T16:54:58.908976Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"sf_permits_with_na_imputed","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:58.911174Z","iopub.execute_input":"2023-07-14T16:54:58.911491Z","iopub.status.idle":"2023-07-14T16:54:59.063037Z","shell.execute_reply.started":"2023-07-14T16:54:58.911462Z","shell.execute_reply":"2023-07-14T16:54:59.061771Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"       Permit Number  Permit Type            Permit Type Definition  \\\n0       201505065519            4                      sign - erect   \n1       201604195146            4                      sign - erect   \n2       201605278609            3  additions alterations or repairs   \n3       201611072166            8            otc alterations permit   \n4       201611283529            6                       demolitions   \n...              ...          ...                               ...   \n198895       M862628            8            otc alterations permit   \n198896  201712055595            8            otc alterations permit   \n198897       M863507            8            otc alterations permit   \n198898       M863747            8            otc alterations permit   \n198899       M864287            8            otc alterations permit   \n\n       Permit Creation Date Block   Lot  Street Number Street Number Suffix  \\\n0                05/06/2015  0326   023            140                    A   \n1                04/19/2016  0306   007            440                    A   \n2                05/27/2016  0595   203           1647                    A   \n3                11/07/2016  0156   011           1230                    A   \n4                11/28/2016  0342   001            950                    A   \n...                     ...   ...   ...            ...                  ...   \n198895           12/05/2017  0113  017A           1228                    0   \n198896           12/05/2017  0271   014            580                    0   \n198897           12/06/2017  4318   019           1568                    0   \n198898           12/06/2017  0298   029            795                    0   \n198899           12/07/2017  0160   006            838                    0   \n\n       Street Name Street Suffix  ...  Existing Construction Type  \\\n0            Ellis            St  ...                         3.0   \n1            Geary            St  ...                         3.0   \n2          Pacific            Av  ...                         1.0   \n3          Pacific            Av  ...                         5.0   \n4           Market            St  ...                         3.0   \n...            ...           ...  ...                         ...   \n198895  Montgomery            St  ...                         5.0   \n198896        Bush            St  ...                         5.0   \n198897     Indiana            St  ...                         0.0   \n198898      Sutter            St  ...                         0.0   \n198899     Pacific            Av  ...                         0.0   \n\n       Existing Construction Type Description Proposed Construction Type  \\\n0                               constr type 3                        1.0   \n1                               constr type 3                        1.0   \n2                               constr type 1                        1.0   \n3                              wood frame (5)                        5.0   \n4                               constr type 3                        1.0   \n...                                       ...                        ...   \n198895                         wood frame (5)                        5.0   \n198896                         wood frame (5)                        5.0   \n198897                                      0                        0.0   \n198898                                      0                        0.0   \n198899                                      0                        0.0   \n\n       Proposed Construction Type Description Site Permit Supervisor District  \\\n0                               constr type 1           Y                 3.0   \n1                               constr type 1           Y                 3.0   \n2                               constr type 1           Y                 3.0   \n3                              wood frame (5)           Y                 3.0   \n4                               constr type 1           Y                 6.0   \n...                                       ...         ...                 ...   \n198895                         wood frame (5)           0                 0.0   \n198896                         wood frame (5)           0                 0.0   \n198897                                      0           0                 0.0   \n198898                                      0           0                 0.0   \n198899                                      0           0                 0.0   \n\n       Neighborhoods - Analysis Boundaries  Zipcode  \\\n0                               Tenderloin  94102.0   \n1                               Tenderloin  94102.0   \n2                             Russian Hill  94109.0   \n3                                 Nob Hill  94109.0   \n4                               Tenderloin  94102.0   \n...                                    ...      ...   \n198895                                   0      0.0   \n198896                                   0      0.0   \n198897                                   0      0.0   \n198898                                   0      0.0   \n198899                                   0      0.0   \n\n                                         Location      Record ID  \n0       (37.785719256680785, -122.40852313194863)  1380611233945  \n1        (37.78733980600732, -122.41063199757738)  1420164406718  \n2         (37.7946573324287, -122.42232562979227)  1424856504716  \n3        (37.79595867909168, -122.41557405519474)  1443574295566  \n4        (37.78315261897309, -122.40950883997789)   144548169992  \n...                                           ...            ...  \n198895                                          0  1489337276729  \n198896                                          0  1489462354993  \n198897                                          0  1489539379952  \n198898                                          0  1489608233656  \n198899                                          0  1489796283803  \n\n[198900 rows x 43 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Permit Number</th>\n      <th>Permit Type</th>\n      <th>Permit Type Definition</th>\n      <th>Permit Creation Date</th>\n      <th>Block</th>\n      <th>Lot</th>\n      <th>Street Number</th>\n      <th>Street Number Suffix</th>\n      <th>Street Name</th>\n      <th>Street Suffix</th>\n      <th>...</th>\n      <th>Existing Construction Type</th>\n      <th>Existing Construction Type Description</th>\n      <th>Proposed Construction Type</th>\n      <th>Proposed Construction Type Description</th>\n      <th>Site Permit</th>\n      <th>Supervisor District</th>\n      <th>Neighborhoods - Analysis Boundaries</th>\n      <th>Zipcode</th>\n      <th>Location</th>\n      <th>Record ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201505065519</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>05/06/2015</td>\n      <td>0326</td>\n      <td>023</td>\n      <td>140</td>\n      <td>A</td>\n      <td>Ellis</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>Y</td>\n      <td>3.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.785719256680785, -122.40852313194863)</td>\n      <td>1380611233945</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>201604195146</td>\n      <td>4</td>\n      <td>sign - erect</td>\n      <td>04/19/2016</td>\n      <td>0306</td>\n      <td>007</td>\n      <td>440</td>\n      <td>A</td>\n      <td>Geary</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>Y</td>\n      <td>3.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.78733980600732, -122.41063199757738)</td>\n      <td>1420164406718</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>201605278609</td>\n      <td>3</td>\n      <td>additions alterations or repairs</td>\n      <td>05/27/2016</td>\n      <td>0595</td>\n      <td>203</td>\n      <td>1647</td>\n      <td>A</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>Y</td>\n      <td>3.0</td>\n      <td>Russian Hill</td>\n      <td>94109.0</td>\n      <td>(37.7946573324287, -122.42232562979227)</td>\n      <td>1424856504716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>201611072166</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>11/07/2016</td>\n      <td>0156</td>\n      <td>011</td>\n      <td>1230</td>\n      <td>A</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>Y</td>\n      <td>3.0</td>\n      <td>Nob Hill</td>\n      <td>94109.0</td>\n      <td>(37.79595867909168, -122.41557405519474)</td>\n      <td>1443574295566</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>201611283529</td>\n      <td>6</td>\n      <td>demolitions</td>\n      <td>11/28/2016</td>\n      <td>0342</td>\n      <td>001</td>\n      <td>950</td>\n      <td>A</td>\n      <td>Market</td>\n      <td>St</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>constr type 3</td>\n      <td>1.0</td>\n      <td>constr type 1</td>\n      <td>Y</td>\n      <td>6.0</td>\n      <td>Tenderloin</td>\n      <td>94102.0</td>\n      <td>(37.78315261897309, -122.40950883997789)</td>\n      <td>144548169992</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>198895</th>\n      <td>M862628</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/05/2017</td>\n      <td>0113</td>\n      <td>017A</td>\n      <td>1228</td>\n      <td>0</td>\n      <td>Montgomery</td>\n      <td>St</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1489337276729</td>\n    </tr>\n    <tr>\n      <th>198896</th>\n      <td>201712055595</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/05/2017</td>\n      <td>0271</td>\n      <td>014</td>\n      <td>580</td>\n      <td>0</td>\n      <td>Bush</td>\n      <td>St</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>5.0</td>\n      <td>wood frame (5)</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1489462354993</td>\n    </tr>\n    <tr>\n      <th>198897</th>\n      <td>M863507</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/06/2017</td>\n      <td>4318</td>\n      <td>019</td>\n      <td>1568</td>\n      <td>0</td>\n      <td>Indiana</td>\n      <td>St</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1489539379952</td>\n    </tr>\n    <tr>\n      <th>198898</th>\n      <td>M863747</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/06/2017</td>\n      <td>0298</td>\n      <td>029</td>\n      <td>795</td>\n      <td>0</td>\n      <td>Sutter</td>\n      <td>St</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1489608233656</td>\n    </tr>\n    <tr>\n      <th>198899</th>\n      <td>M864287</td>\n      <td>8</td>\n      <td>otc alterations permit</td>\n      <td>12/07/2017</td>\n      <td>0160</td>\n      <td>006</td>\n      <td>838</td>\n      <td>0</td>\n      <td>Pacific</td>\n      <td>Av</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1489796283803</td>\n    </tr>\n  </tbody>\n</table>\n<p>198900 rows × 43 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Approaches - Missing Values\nhttps://www.kaggle.com/code/alexisbcook/missing-values/tutorial","metadata":{}},{"cell_type":"markdown","source":"1. * **Simple column drop**\n1. * **Imputation - fill with values (e.g. mean of non-null values)**\n1. * **Imputation extended - Apply imputation with a new 'flag' column (boolean) - '_was_missing'**","metadata":{}},{"cell_type":"code","source":"# import modules\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load the data (Melbourne Housing Data)\ndata = pd.read_csv(\"/kaggle/input/melbourne-housing-snapshot/melb_data.csv\")\n\n# quick data review\ndata.head() # 5x21","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:59.064752Z","iopub.execute_input":"2023-07-14T16:54:59.065372Z","iopub.status.idle":"2023-07-14T16:54:59.706652Z","shell.execute_reply.started":"2023-07-14T16:54:59.065337Z","shell.execute_reply":"2023-07-14T16:54:59.704896Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"       Suburb           Address  Rooms Type      Price Method SellerG  \\\n0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n\n        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n0  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n3  4/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n\n   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n\n  Propertycount  \n0        4019.0  \n1        4019.0  \n2        4019.0  \n3        4019.0  \n4        4019.0  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Suburb</th>\n      <th>Address</th>\n      <th>Rooms</th>\n      <th>Type</th>\n      <th>Price</th>\n      <th>Method</th>\n      <th>SellerG</th>\n      <th>Date</th>\n      <th>Distance</th>\n      <th>Postcode</th>\n      <th>...</th>\n      <th>Bathroom</th>\n      <th>Car</th>\n      <th>Landsize</th>\n      <th>BuildingArea</th>\n      <th>YearBuilt</th>\n      <th>CouncilArea</th>\n      <th>Lattitude</th>\n      <th>Longtitude</th>\n      <th>Regionname</th>\n      <th>Propertycount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abbotsford</td>\n      <td>85 Turner St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1480000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>3/12/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>202.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7996</td>\n      <td>144.9984</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abbotsford</td>\n      <td>25 Bloomburg St</td>\n      <td>2</td>\n      <td>h</td>\n      <td>1035000.0</td>\n      <td>S</td>\n      <td>Biggin</td>\n      <td>4/02/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>156.0</td>\n      <td>79.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8079</td>\n      <td>144.9934</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abbotsford</td>\n      <td>5 Charles St</td>\n      <td>3</td>\n      <td>h</td>\n      <td>1465000.0</td>\n      <td>SP</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>134.0</td>\n      <td>150.0</td>\n      <td>1900.0</td>\n      <td>Yarra</td>\n      <td>-37.8093</td>\n      <td>144.9944</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abbotsford</td>\n      <td>40 Federation La</td>\n      <td>3</td>\n      <td>h</td>\n      <td>850000.0</td>\n      <td>PI</td>\n      <td>Biggin</td>\n      <td>4/03/2017</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>94.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Yarra</td>\n      <td>-37.7969</td>\n      <td>144.9969</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abbotsford</td>\n      <td>55a Park St</td>\n      <td>4</td>\n      <td>h</td>\n      <td>1600000.0</td>\n      <td>VB</td>\n      <td>Nelson</td>\n      <td>4/06/2016</td>\n      <td>2.5</td>\n      <td>3067.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>120.0</td>\n      <td>142.0</td>\n      <td>2014.0</td>\n      <td>Yarra</td>\n      <td>-37.8072</td>\n      <td>144.9941</td>\n      <td>Northern Metropolitan</td>\n      <td>4019.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Set prediction target value\ny = data.Price","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:59.708267Z","iopub.execute_input":"2023-07-14T16:54:59.708628Z","iopub.status.idle":"2023-07-14T16:54:59.714638Z","shell.execute_reply.started":"2023-07-14T16:54:59.708574Z","shell.execute_reply":"2023-07-14T16:54:59.712792Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Set predictors (input variables, independent variables, features, estimators, to predict the target)\n# Here, using only numerical values for preditors, to exlcude other data types\n\n# drop 'Price' column\nmelb_predictors = data.drop(['Price'], axis=1)\n\n# check the result data frame\nprint(melb_predictors.head())\n\n# check the data types in the data to decide what types to be included / excluded\n# Will only use numerical types for this project\nprint(melb_predictors.dtypes) # column-data_type\nprint(melb_predictors.dtypes.value_counts()) # data_type - count\nX = melb_predictors.select_dtypes(exclude = ['object']) # drop the columns in 'object' type\nprint(X)\n\n# split the data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# Apply three missing-value handling approaches above to the model\n# and measure the each performance for comparison. \n\n# Will use RandomFrestRegressor model for training / MAE for accuracy measurement\n# Define a function to do them.","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:59.716185Z","iopub.execute_input":"2023-07-14T16:54:59.716485Z","iopub.status.idle":"2023-07-14T16:54:59.759478Z","shell.execute_reply.started":"2023-07-14T16:54:59.716461Z","shell.execute_reply":"2023-07-14T16:54:59.758590Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"       Suburb           Address  Rooms Type Method SellerG       Date  \\\n0  Abbotsford      85 Turner St      2    h      S  Biggin  3/12/2016   \n1  Abbotsford   25 Bloomburg St      2    h      S  Biggin  4/02/2016   \n2  Abbotsford      5 Charles St      3    h     SP  Biggin  4/03/2017   \n3  Abbotsford  40 Federation La      3    h     PI  Biggin  4/03/2017   \n4  Abbotsford       55a Park St      4    h     VB  Nelson  4/06/2016   \n\n   Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  BuildingArea  \\\n0       2.5    3067.0       2.0       1.0  1.0     202.0           NaN   \n1       2.5    3067.0       2.0       1.0  0.0     156.0          79.0   \n2       2.5    3067.0       3.0       2.0  0.0     134.0         150.0   \n3       2.5    3067.0       3.0       2.0  1.0      94.0           NaN   \n4       2.5    3067.0       3.0       1.0  2.0     120.0         142.0   \n\n   YearBuilt CouncilArea  Lattitude  Longtitude             Regionname  \\\n0        NaN       Yarra   -37.7996    144.9984  Northern Metropolitan   \n1     1900.0       Yarra   -37.8079    144.9934  Northern Metropolitan   \n2     1900.0       Yarra   -37.8093    144.9944  Northern Metropolitan   \n3        NaN       Yarra   -37.7969    144.9969  Northern Metropolitan   \n4     2014.0       Yarra   -37.8072    144.9941  Northern Metropolitan   \n\n   Propertycount  \n0         4019.0  \n1         4019.0  \n2         4019.0  \n3         4019.0  \n4         4019.0  \nSuburb            object\nAddress           object\nRooms              int64\nType              object\nMethod            object\nSellerG           object\nDate              object\nDistance         float64\nPostcode         float64\nBedroom2         float64\nBathroom         float64\nCar              float64\nLandsize         float64\nBuildingArea     float64\nYearBuilt        float64\nCouncilArea       object\nLattitude        float64\nLongtitude       float64\nRegionname        object\nPropertycount    float64\ndtype: object\nfloat64    11\nobject      8\nint64       1\ndtype: int64\n       Rooms  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n0          2       2.5    3067.0       2.0       1.0  1.0     202.0   \n1          2       2.5    3067.0       2.0       1.0  0.0     156.0   \n2          3       2.5    3067.0       3.0       2.0  0.0     134.0   \n3          3       2.5    3067.0       3.0       2.0  1.0      94.0   \n4          4       2.5    3067.0       3.0       1.0  2.0     120.0   \n...      ...       ...       ...       ...       ...  ...       ...   \n13575      4      16.7    3150.0       4.0       2.0  2.0     652.0   \n13576      3       6.8    3016.0       3.0       2.0  2.0     333.0   \n13577      3       6.8    3016.0       3.0       2.0  4.0     436.0   \n13578      4       6.8    3016.0       4.0       1.0  5.0     866.0   \n13579      4       6.3    3013.0       4.0       1.0  1.0     362.0   \n\n       BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n0               NaN        NaN  -37.79960   144.99840         4019.0  \n1              79.0     1900.0  -37.80790   144.99340         4019.0  \n2             150.0     1900.0  -37.80930   144.99440         4019.0  \n3               NaN        NaN  -37.79690   144.99690         4019.0  \n4             142.0     2014.0  -37.80720   144.99410         4019.0  \n...             ...        ...        ...         ...            ...  \n13575           NaN     1981.0  -37.90562   145.16761         7392.0  \n13576         133.0     1995.0  -37.85927   144.87904         6380.0  \n13577           NaN     1997.0  -37.85274   144.88738         6380.0  \n13578         157.0     1920.0  -37.85908   144.89299         6380.0  \n13579         112.0     1920.0  -37.81188   144.88449         6543.0  \n\n[13580 rows x 12 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# function for comparing different approaches\n# Define a model, train, predict and evaluate using a training / validation datasets\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    # define a model - here, using Radom Forest\n    model = RandomForestRegressor(n_estimators=10, random_state=0)\n    # fit the model - training\n    model.fit(X_train, y_train)\n    # predict with the model\n    preds = model.predict(X_valid)\n    \n    # return the MAE performance \n    return mean_absolute_error(y_valid, preds)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:54:59.760488Z","iopub.execute_input":"2023-07-14T16:54:59.760866Z","iopub.status.idle":"2023-07-14T16:55:00.142650Z","shell.execute_reply.started":"2023-07-14T16:54:59.760832Z","shell.execute_reply":"2023-07-14T16:55:00.141146Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"**Try each approach of handing missing-value of the dataset, and train and test the model**","metadata":{}},{"cell_type":"markdown","source":"**Approach 1: Simple Drop columns with missing values**","metadata":{}},{"cell_type":"code","source":"# What columns are with missing values?\n\n# get columns with missing values\ncols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()] # if any value in a column is True, meaning missing value in this example, save it to a list using list comprehension\n\n# drop the selected columns, on botth training / validation dataset\nreduced_X_train = X_train.drop(cols_with_missing, axis = 1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis = 1)\n\n# Use the helper function to create a model, train and MAE peformance measurement.\nprint(\"MAE from Approach 1 (Drop columns with missing values.)\")\nscore_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid) # 183550.22137772635\n\n#print(X_train.columns)\n#is_na = X_train.columns.isnull()\n#type(is_na)\n#help(X_train.columns.isnull)\n#help(is_na.any)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T16:55:00.146589Z","iopub.execute_input":"2023-07-14T16:55:00.146917Z","iopub.status.idle":"2023-07-14T16:55:00.616424Z","shell.execute_reply.started":"2023-07-14T16:55:00.146893Z","shell.execute_reply":"2023-07-14T16:55:00.615072Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"MAE from Approach 1 (Drop columns with missing values.)\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"183550.22137772635"},"metadata":{}}]},{"cell_type":"markdown","source":"**Approach 2. Imputation**   \nSimpleImputation from scikit-learn, by default, replacing the NaN with mean value of the column    \n    \n* imputed_X_train = pd.DataFrame(my_imputer.**fit_transform(X_train)**) performs imputation on the training data X_train using the fit_transform() method. The fit_transform() method fits the imputer to the training data and transforms it in a single step. The missing values are replaced with the appropriate imputed values, and the result is converted into a new Pandas DataFrame imputed_X_train.\n\n* imputed_X_valid = pd.DataFrame(my_imputer.**transform(X_valid)**) applies the same imputer instance to the validation data X_valid using the transform() method. **The transform() method applies the learned imputation strategy from the training data to the validation data.** The missing values in X_valid are replaced with imputed values, and the result is converted into a new Pandas DataFrame imputed_X_valid.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train)) # impute the X_train with missing values --> df\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid)) # impute the X_valid with the same stratigies used in X_train imputation\n\n# Restore columns removed during imputation\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\n# Use the helper function to create a model, train and MAE peformance measurement.\nprint(\"MAE from Approach 2 (Imputation):\")\nscore_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid)  # 178166.46269899711\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:28:56.610183Z","iopub.execute_input":"2023-07-14T17:28:56.610587Z","iopub.status.idle":"2023-07-14T17:28:57.195429Z","shell.execute_reply.started":"2023-07-14T17:28:56.610558Z","shell.execute_reply":"2023-07-14T17:28:57.193949Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"MAE from Approach 2 (Imputation):\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"178166.46269899711"},"metadata":{}}]},{"cell_type":"markdown","source":"**We see that Approach 2 has lower MAE than Approach 1, so Approach 2 performed better on this dataset.**","metadata":{}},{"cell_type":"markdown","source":"**Approach 3 (An Extension to Imputation)**    \nImpute the missing values, while also keeping track of which values were imputed, adding _missing_value","metadata":{}},{"cell_type":"code","source":"# Will be adding columns to track the missing values, work it on copy of the dataset.\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:29:02.891881Z","iopub.execute_input":"2023-07-14T17:29:02.892248Z","iopub.status.idle":"2023-07-14T17:29:02.897949Z","shell.execute_reply.started":"2023-07-14T17:29:02.892223Z","shell.execute_reply":"2023-07-14T17:29:02.897096Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# use the list of columns containing any missing values created earlier\n# create a new column with suffix '_missing_value'\nfor col in cols_with_missing:\n    X_train_plus[col + '_missing_value'] = X_train_plus[col].isnull() # set values for the column True/False\n    X_valid_plus[col + '_missing_value'] = X_valid_plus[col].isnull() # set values for the column True/False\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus)) # impute, column labels to be lost\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))     # impute the same way as done on X_train, column labesl to be lost\n\n# Restore the column labels\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\n# Use the helper function to create a model, train and MAE peformance measurement.\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nscore_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid)  # 178927.503183954","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:29:07.420703Z","iopub.execute_input":"2023-07-14T17:29:07.421041Z","iopub.status.idle":"2023-07-14T17:29:08.055075Z","shell.execute_reply.started":"2023-07-14T17:29:07.421012Z","shell.execute_reply":"2023-07-14T17:29:08.054101Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"MAE from Approach 3 (An Extension to Imputation):\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"178927.503183954"},"metadata":{}}]},{"cell_type":"markdown","source":"**As we can see, Approach 3 performed slightly worse than Approach 2.**","metadata":{}},{"cell_type":"markdown","source":"## So, why did imputation perform better than dropping the columns?","metadata":{}},{"cell_type":"markdown","source":"> **The training data has 10864 rows and 12 columns, where three columns contain missing data. For each column, less than half of the entries are missing. Thus, *dropping the columns removes a lot of useful information*, and so it makes sense that imputation would perform better.**","metadata":{}},{"cell_type":"code","source":"# shape of the training data\nprint(X_train.shape) # (10864, 12)\n\n# value count by column\nvalue_count = X_train.isnull().sum()\nmissing_value_count = value_count[value_count > 0]\nprint(missing_value_count)\n\n# total missing value count\ntotal_missing_value_count = X_train.isnull().sum().sum() # trick to add up all TRUE's as 1's - 9512\nprint(total_missing_value_count)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:53:27.739740Z","iopub.execute_input":"2023-07-14T17:53:27.740084Z","iopub.status.idle":"2023-07-14T17:53:27.750974Z","shell.execute_reply.started":"2023-07-14T17:53:27.740058Z","shell.execute_reply":"2023-07-14T17:53:27.749207Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"(10864, 12)\nCar               49\nBuildingArea    5156\nYearBuilt       4307\ndtype: int64\n9512\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:48:52.656822Z","iopub.execute_input":"2023-07-14T17:48:52.657749Z","iopub.status.idle":"2023-07-14T17:48:52.665102Z","shell.execute_reply.started":"2023-07-14T17:48:52.657699Z","shell.execute_reply":"2023-07-14T17:48:52.663662Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"9512"},"metadata":{}}]},{"cell_type":"code","source":"value_count\nmissing_value_count\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T17:52:34.943933Z","iopub.execute_input":"2023-07-14T17:52:34.944322Z","iopub.status.idle":"2023-07-14T17:52:34.950409Z","shell.execute_reply.started":"2023-07-14T17:52:34.944293Z","shell.execute_reply":"2023-07-14T17:52:34.949790Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"Car               49\nBuildingArea    5156\nYearBuilt       4307\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion\n### As is common, imputing missing values (in Approach 2 and Approach 3) yielded better results, relative to when we simply dropped columns with missing values (in Approach 1).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}